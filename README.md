### 1.èƒŒæ™¯æ„ä¹‰

ç ”ç©¶èƒŒæ™¯ä¸æ„ä¹‰

éšç€å·¥ä¸šè‡ªåŠ¨åŒ–å’Œæ™ºèƒ½åˆ¶é€ çš„è¿…é€Ÿå‘å±•ï¼Œå·¥äººå®‰å…¨é—®é¢˜æ—¥ç›Šå—åˆ°é‡è§†ã€‚ç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠé‡å‹æœºæ¢°å’Œå±é™©æ“ä½œçš„å·¥ä½œç¯å¢ƒä¸­ï¼Œå·¥äººæ‰‹éƒ¨çš„å®‰å…¨ä¿æŠ¤æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚ä¼ ç»Ÿçš„å®‰å…¨æ‰‹å¥—è™½ç„¶åœ¨ä¸€å®šç¨‹åº¦ä¸Šèƒ½å¤Ÿä¿æŠ¤å·¥äººçš„æ‰‹éƒ¨ï¼Œä½†åœ¨å¤æ‚çš„åŠ å·¥æ“ä½œä¸­ï¼Œå¦‚ä½•å®æ—¶ç›‘æµ‹æ‰‹éƒ¨çš„çŠ¶æ€å’Œå®‰å…¨æ€§ï¼Œæˆä¸ºäº†ä¸€ä¸ªäºŸå¾…è§£å†³çš„æŠ€æœ¯éš¾é¢˜ã€‚å› æ­¤ï¼Œå¼€å‘ä¸€ä¸ªåŸºäºå…ˆè¿›è®¡ç®—æœºè§†è§‰æŠ€æœ¯çš„æ‰‹éƒ¨æ£€æµ‹ç³»ç»Ÿï¼Œä¸ä»…å¯ä»¥æé«˜å·¥äººçš„å®‰å…¨æ€§ï¼Œè¿˜èƒ½æå‡ç”Ÿäº§æ•ˆç‡ã€‚

æœ¬ç ”ç©¶æ—¨åœ¨åŸºäºæ”¹è¿›çš„YOLOv11æ¨¡å‹ï¼Œæ„å»ºä¸€ä¸ªé«˜æ•ˆçš„åŠ å·¥æ“ä½œå®‰å…¨æ‰‹å¥—ä¸æ‰‹éƒ¨æ£€æµ‹ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿå°†åˆ©ç”¨åŒ…å«1500å¼ å›¾åƒçš„bandsaw_kolabiraæ•°æ®é›†è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ã€‚æ•°æ®é›†ä¸­åŒ…å«äº†å¤šç§æ‰‹å¥—å’Œæ‰‹éƒ¨çš„ç±»åˆ«ï¼ŒåŒ…æ‹¬è“è‰²æ‰‹å¥—ã€ç™½è‰²æ‰‹å¥—ã€é’¢åˆ¶æ‰‹å¥—ä»¥åŠæ‰‹éƒ¨å’Œå¤´éƒ¨çš„æ ‡æ³¨ä¿¡æ¯ã€‚è¿™äº›å¤šæ ·åŒ–çš„ç±»åˆ«ä¸ºæ¨¡å‹çš„è®­ç»ƒæä¾›äº†ä¸°å¯Œçš„æ ·æœ¬ï¼Œæœ‰åŠ©äºæé«˜æ¨¡å‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¯¥ç³»ç»Ÿå°†èƒ½å¤Ÿå®æ—¶è¯†åˆ«å·¥äººæ˜¯å¦ä½©æˆ´å®‰å…¨æ‰‹å¥—ï¼Œå¹¶ç›‘æµ‹æ‰‹éƒ¨çš„æ´»åŠ¨çŠ¶æ€ï¼Œä»è€Œæœ‰æ•ˆé¢„é˜²å› æ“ä½œä¸å½“å¯¼è‡´çš„å®‰å…¨äº‹æ•…ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¯¹æ‰‹éƒ¨çŠ¶æ€çš„ç›‘æµ‹ï¼Œç³»ç»Ÿè¿˜å¯ä»¥ä¸ºå·¥äººæä¾›å®æ—¶åé¦ˆï¼Œå¸®åŠ©å…¶è°ƒæ•´æ“ä½œå§¿åŠ¿ï¼Œé™ä½å—ä¼¤é£é™©ã€‚é€šè¿‡å°†è®¡ç®—æœºè§†è§‰æŠ€æœ¯ä¸å·¥äººå®‰å…¨ç®¡ç†ç›¸ç»“åˆï¼Œæœ¬ç ”ç©¶ä¸ä»…ä¸ºå®‰å…¨ç”Ÿäº§æä¾›äº†æŠ€æœ¯æ”¯æŒï¼Œä¹Ÿä¸ºæœªæ¥æ™ºèƒ½åˆ¶é€ çš„å‘å±•æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹å‘ã€‚

### 2.è§†é¢‘æ•ˆæœ

[2.1 è§†é¢‘æ•ˆæœ](https://www.bilibili.com/video/BV1joqLY6EhS/)

### 3.å›¾ç‰‡æ•ˆæœ

![1.png](1.png)

![2.png](2.png)

![3.png](3.png)

##### [é¡¹ç›®æ¶‰åŠçš„æºç æ•°æ®æ¥æºé“¾æ¥](https://kdocs.cn/l/cszuIiCKVNis)**

æ³¨æ„ï¼šæœ¬é¡¹ç›®æä¾›è®­ç»ƒçš„æ•°æ®é›†å’Œè®­ç»ƒæ•™ç¨‹,ç”±äºç‰ˆæœ¬æŒç»­æ›´æ–°,æš‚ä¸æä¾›æƒé‡æ–‡ä»¶ï¼ˆbest.ptï¼‰,è¯·æŒ‰ç…§6.è®­ç»ƒæ•™ç¨‹è¿›è¡Œè®­ç»ƒåå®ç°ä¸Šå›¾æ¼”ç¤ºçš„æ•ˆæœã€‚

### 4.æ•°æ®é›†ä¿¡æ¯

##### 4.1 æœ¬é¡¹ç›®æ•°æ®é›†ç±»åˆ«æ•°ï¼†ç±»åˆ«å

nc: 6
names: ['Glove_Blue', 'Glove_White', 'glove_steel', 'glove_steel_b', 'hand', 'head']



è¯¥é¡¹ç›®ä¸ºã€å›¾åƒåˆ†å‰²ã€‘æ•°æ®é›†ï¼Œè¯·åœ¨ã€è®­ç»ƒæ•™ç¨‹å’ŒWebç«¯åŠ è½½æ¨¡å‹æ•™ç¨‹ï¼ˆç¬¬ä¸‰æ­¥ï¼‰ã€‘è¿™ä¸€æ­¥çš„æ—¶å€™æŒ‰ç…§ã€å›¾åƒåˆ†å‰²ã€‘éƒ¨åˆ†çš„æ•™ç¨‹æ¥è®­ç»ƒ

##### 4.2 æœ¬é¡¹ç›®æ•°æ®é›†ä¿¡æ¯ä»‹ç»

æœ¬é¡¹ç›®æ•°æ®é›†ä¿¡æ¯ä»‹ç»

æœ¬é¡¹ç›®æ—¨åœ¨æ”¹è¿›YOLOv11çš„åŠ å·¥æ“ä½œå®‰å…¨æ‰‹å¥—ä¸æ‰‹éƒ¨æ£€æµ‹ç³»ç»Ÿï¼Œæ‰€ä½¿ç”¨çš„æ•°æ®é›†å›´ç»•â€œbandsaw_kolabiraâ€ä¸»é¢˜æ„å»ºï¼Œä¸“æ³¨äºæå‡åœ¨åŠ å·¥ç¯å¢ƒä¸­å¯¹æ‰‹éƒ¨åŠæ‰‹å¥—çš„æ£€æµ‹èƒ½åŠ›ã€‚è¯¥æ•°æ®é›†åŒ…å«å…­ä¸ªç±»åˆ«ï¼Œå…·ä½“ä¸ºï¼šè“è‰²æ‰‹å¥—ï¼ˆGlove_Blueï¼‰ã€ç™½è‰²æ‰‹å¥—ï¼ˆGlove_Whiteï¼‰ã€é’¢åˆ¶æ‰‹å¥—ï¼ˆglove_steelï¼‰ã€é’¢åˆ¶æ‰‹å¥—Bå‹ï¼ˆglove_steel_bï¼‰ã€æ‰‹éƒ¨ï¼ˆhandï¼‰ä»¥åŠå¤´éƒ¨ï¼ˆheadï¼‰ã€‚è¿™äº›ç±»åˆ«çš„é€‰æ‹©æ—¨åœ¨å…¨é¢è¦†ç›–åŠ å·¥æ“ä½œä¸­å¯èƒ½å‡ºç°çš„å…³é”®å®‰å…¨å…ƒç´ ï¼Œç¡®ä¿ç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å¹¶å“åº”ä¸åŒçš„å®‰å…¨é£é™©ã€‚

åœ¨æ•°æ®é›†çš„æ„å»ºè¿‡ç¨‹ä¸­ï¼Œé‡‡é›†äº†å¤§é‡åœ¨å®é™…åŠ å·¥ç¯å¢ƒä¸­æ‹æ‘„çš„å›¾åƒï¼Œç¡®ä¿æ•°æ®çš„å¤šæ ·æ€§å’ŒçœŸå®æ€§ã€‚è¿™äº›å›¾åƒä¸ä»…æ¶µç›–äº†ä¸åŒçš„å…‰ç…§æ¡ä»¶å’ŒèƒŒæ™¯ç¯å¢ƒï¼Œè¿˜åŒ…æ‹¬äº†å„ç§æ‰‹éƒ¨åŠ¨ä½œå’Œæ‰‹å¥—ä½©æˆ´çŠ¶æ€ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ•°æ®é›†èƒ½å¤Ÿæœ‰æ•ˆæ¨¡æ‹ŸçœŸå®å·¥ä½œåœºæ™¯ä¸­å¯èƒ½é‡åˆ°çš„å„ç§æƒ…å†µï¼Œä»è€Œä¸ºYOLOv11æ¨¡å‹çš„è®­ç»ƒæä¾›åšå®çš„åŸºç¡€ã€‚

åœ¨æ•°æ®é›†çš„æ ‡æ³¨è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç²¾ç¡®çš„è¾¹ç•Œæ¡†æ ‡æ³¨æŠ€æœ¯ï¼Œä»¥ç¡®ä¿æ¯ä¸ªç±»åˆ«çš„ç‰©ä½“éƒ½èƒ½è¢«å‡†ç¡®è¯†åˆ«ã€‚æ ‡æ³¨çš„è´¨é‡ç›´æ¥å½±å“åˆ°æ¨¡å‹çš„æ€§èƒ½ï¼Œå› æ­¤æˆ‘ä»¬ç‰¹åˆ«æ³¨é‡æ ‡æ³¨çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œä¸ºäº†æå‡æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ï¼Œæ•°æ®é›†ä¸­è¿˜åŒ…å«äº†ä¸€äº›ç‰¹æ®Šæƒ…å†µçš„æ ·æœ¬ï¼Œä¾‹å¦‚æ‰‹å¥—æœªä½©æˆ´ã€ä½©æˆ´ä¸å½“ç­‰æƒ…å½¢ï¼Œä»¥ä¾¿æ¨¡å‹èƒ½å¤Ÿåœ¨å„ç§æƒ…å†µä¸‹åšå‡ºæ­£ç¡®çš„åˆ¤æ–­ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œæœ¬é¡¹ç›®çš„æ•°æ®é›†ä¸ä»…æ¶µç›–äº†å¤šæ ·çš„ç±»åˆ«å’Œä¸°å¯Œçš„æ ·æœ¬ï¼Œè¿˜æ³¨é‡äº†æ ‡æ³¨çš„ç²¾ç¡®æ€§ä¸åœºæ™¯çš„å¤šæ ·æ€§ï¼Œä¸ºæ”¹è¿›YOLOv11çš„åŠ å·¥æ“ä½œå®‰å…¨æ‰‹å¥—ä¸æ‰‹éƒ¨æ£€æµ‹ç³»ç»Ÿæä¾›äº†å¼ºæœ‰åŠ›çš„æ•°æ®æ”¯æŒã€‚é€šè¿‡å¯¹è¯¥æ•°æ®é›†çš„æ·±å…¥åˆ†æä¸åº”ç”¨ï¼Œæˆ‘ä»¬æœŸæœ›èƒ½å¤Ÿæ˜¾è‘—æå‡ç³»ç»Ÿåœ¨å®é™…åŠ å·¥ç¯å¢ƒä¸­çš„å®‰å…¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

![4.png](4.png)

![5.png](5.png)

![6.png](6.png)

![7.png](7.png)

![8.png](8.png)

### 5.å…¨å¥—é¡¹ç›®ç¯å¢ƒéƒ¨ç½²è§†é¢‘æ•™ç¨‹ï¼ˆé›¶åŸºç¡€æ‰‹æŠŠæ‰‹æ•™å­¦ï¼‰

[5.1 æ‰€éœ€è½¯ä»¶PyCharmå’ŒAnacondaå®‰è£…æ•™ç¨‹ï¼ˆç¬¬ä¸€æ­¥ï¼‰](https://www.bilibili.com/video/BV1BoC1YCEKi/?spm_id_from=333.999.0.0&vd_source=bc9aec86d164b67a7004b996143742dc)




[5.2 å®‰è£…Pythonè™šæ‹Ÿç¯å¢ƒåˆ›å»ºå’Œä¾èµ–åº“å®‰è£…è§†é¢‘æ•™ç¨‹ï¼ˆç¬¬äºŒæ­¥ï¼‰](https://www.bilibili.com/video/BV1ZoC1YCEBw?spm_id_from=333.788.videopod.sections&vd_source=bc9aec86d164b67a7004b996143742dc)

### 6.æ”¹è¿›YOLOv11è®­ç»ƒæ•™ç¨‹å’ŒWeb_UIå‰ç«¯åŠ è½½æ¨¡å‹æ•™ç¨‹ï¼ˆé›¶åŸºç¡€æ‰‹æŠŠæ‰‹æ•™å­¦ï¼‰

[6.1 æ”¹è¿›YOLOv11è®­ç»ƒæ•™ç¨‹å’ŒWeb_UIå‰ç«¯åŠ è½½æ¨¡å‹æ•™ç¨‹ï¼ˆç¬¬ä¸‰æ­¥ï¼‰](https://www.bilibili.com/video/BV1BoC1YCEhR?spm_id_from=333.788.videopod.sections&vd_source=bc9aec86d164b67a7004b996143742dc)


æŒ‰ç…§ä¸Šé¢çš„è®­ç»ƒè§†é¢‘æ•™ç¨‹é“¾æ¥åŠ è½½é¡¹ç›®æä¾›çš„æ•°æ®é›†ï¼Œè¿è¡Œtrain.pyå³å¯å¼€å§‹è®­ç»ƒ
ï»¿


     Epoch   gpu_mem       box       obj       cls    labels  img_size
     1/200     20.8G   0.01576   0.01955  0.007536        22      1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [14:42<00:00,  1.04s/it]
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [01:14<00:00,  2.87it/s]
                 all       3395      17314      0.994      0.957      0.0957      0.0843

     Epoch   gpu_mem       box       obj       cls    labels  img_size
     2/200     20.8G   0.01578   0.01923  0.007006        22      1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [14:44<00:00,  1.04s/it]
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/213 [01:12<00:00,  2.95it/s]
                 all       3395      17314      0.996      0.956      0.0957      0.0845

     Epoch   gpu_mem       box       obj       cls    labels  img_size
     3/200     20.8G   0.01561    0.0191  0.006895        27      1280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 849/849 [10:56<00:00,  1.29it/s]
               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 187/213 [00:52<00:00,  4.04it/s]
                 all       3395      17314      0.996      0.957      0.0957      0.0845




###### [é¡¹ç›®æ•°æ®é›†ä¸‹è½½é“¾æ¥](https://kdocs.cn/l/cszuIiCKVNis)

### 7.åŸå§‹YOLOv11ç®—æ³•è®²è§£

YOLOv11æ˜¯Ultralyticsæ¨å‡ºçš„YOLOç³»åˆ—æœ€æ–°ç‰ˆæœ¬ï¼Œä¸“ä¸ºå®ç°å°–ç«¯çš„ç‰©ä½“æ£€æµ‹è€Œè®¾è®¡ã€‚å…¶æ¶æ„å’Œè®­ç»ƒæ–¹æ³•ä¸Šè¿›è¡Œäº†é‡å¤§æ”¹è¿›ï¼Œä½¿ä¹‹ä¸ä»…å…·å¤‡å“è¶Šçš„å‡†ç¡®æ€§å’Œå¤„ç†é€Ÿåº¦ï¼Œè¿˜åœ¨è®¡ç®—æ•ˆç‡ä¸Šå®ç°äº†ä¸€åœºé©å‘½ã€‚å¾—ç›Šäºå…¶æ”¹è¿›çš„ä¸»å¹²å’Œé¢ˆéƒ¨æ¶æ„ï¼ŒYOLOv11åœ¨ç‰¹å¾æå–å’Œå¤„ç†å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°æ›´åŠ å‡ºè‰²ã€‚åœ¨2024å¹´9æœˆ27æ—¥ï¼ŒUltralyticsé€šè¿‡é•¿è¾¾ä¹å°æ—¶çš„åœ¨çº¿ç›´æ’­å‘å¸ƒè¿™ä¸€æ–°ä½œï¼Œå±•ç¤ºäº†å…¶åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„é©æ–°ã€‚

YOLOv11é€šè¿‡ç²¾ç»†çš„æ¶æ„è®¾è®¡å’Œä¼˜åŒ–è®­ç»ƒæµç¨‹ï¼Œåœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶ï¼Œç¼©å‡äº†å‚æ•°é‡ï¼Œä¸YOLOv8mç›¸æ¯”å‡å°‘äº†22%çš„å‚æ•°ï¼Œä½¿å…¶åœ¨COCOæ•°æ®é›†ä¸Šçš„å¹³å‡å‡†ç¡®åº¦ï¼ˆmAPï¼‰æœ‰æ‰€æå‡ã€‚è¿™ç§æ•ˆç‡çš„æé«˜ä½¿YOLOv11éå¸¸é€‚åˆéƒ¨ç½²åœ¨å„ç§ç¡¬ä»¶ç¯å¢ƒä¸­ï¼ŒåŒ…æ‹¬è¾¹ç¼˜è®¾å¤‡ã€äº‘è®¡ç®—å¹³å°ä»¥åŠæ”¯æŒNVIDIA GPUçš„ç³»ç»Ÿï¼Œç¡®ä¿åœ¨çµæ´»æ€§ä¸Šçš„ä¼˜åŠ¿ã€‚

è¯¥æ¨¡å‹æ”¯æŒå¹¿æ³›çš„ä»»åŠ¡ï¼Œä»å¯¹è±¡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²åˆ°å›¾åƒåˆ†ç±»ã€å§¿æ€ä¼°è®¡å’Œå®šå‘å¯¹è±¡æ£€æµ‹ï¼ˆOBBï¼‰ï¼Œå‡ ä¹è¦†ç›–äº†è®¡ç®—æœºè§†è§‰çš„æ‰€æœ‰ä¸»è¦æŒ‘æˆ˜ã€‚å…¶åˆ›æ–°çš„C3k2å’ŒC2PSAæ¨¡å—æå‡äº†ç½‘ç»œæ·±åº¦å’Œæ³¨æ„åŠ›æœºåˆ¶çš„åº”ç”¨ï¼Œæé«˜äº†ç‰¹å¾æå–çš„æ•ˆç‡å’Œæ•ˆæœã€‚åŒæ—¶ï¼ŒYOLOv11çš„æ”¹è¿›ç½‘ç»œç»“æ„ä¹Ÿä½¿ä¹‹åœ¨å¤æ‚è§†è§‰ä»»åŠ¡ä¸Šå¾—ä»¥ä»å®¹åº”å¯¹ï¼Œæˆä¸ºå„ç±»è®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„å¤šåŠŸèƒ½é€‰æ‹©ã€‚è¿™äº›ç‰¹æ€§ä»¤YOLOv11åœ¨å®æ–½å®æ—¶ç‰©ä½“æ£€æµ‹çš„å„ä¸ªé¢†åŸŸä¸­è¡¨ç°å‡ºä¼—ã€‚
* * *

2024å¹´9æœˆ27æ—¥ï¼ŒUltralyticsåœ¨çº¿ç›´æ’­é•¿è¾¾ä¹å°æ—¶ï¼Œä¸ºYOLO11å¬å¼€â€œå‘å¸ƒä¼šâ€

YOLO11 æ˜¯ Ultralytics YOLO ç³»åˆ—å®æ—¶ç‰©ä½“æ£€æµ‹å™¨çš„æœ€æ–°ç‰ˆæœ¬ï¼Œå®ƒä»¥å°–ç«¯çš„å‡†ç¡®æ€§ã€é€Ÿåº¦å’Œæ•ˆç‡é‡æ–°å®šä¹‰äº†å¯èƒ½æ€§ã€‚åœ¨ä¹‹å‰ YOLO
ç‰ˆæœ¬çš„æ˜¾è‘—è¿›æ­¥çš„åŸºç¡€ä¸Šï¼ŒYOLO11 åœ¨æ¶æ„å’Œè®­ç»ƒæ–¹æ³•æ–¹é¢è¿›è¡Œäº†é‡å¤§æ”¹è¿›ï¼Œä½¿å…¶æˆä¸ºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„å¤šåŠŸèƒ½é€‰æ‹©ã€‚

![](https://i-blog.csdnimg.cn/direct/a4e1a178833746249720ccee1c82a58b.png)

##### YOLO11ä¸»è¦ç‰¹ç‚¹ï¼š

  * å¢å¼ºçš„ç‰¹å¾æå–ï¼šYOLO11 é‡‡ç”¨äº†æ”¹è¿›çš„ä¸»å¹²å’Œé¢ˆéƒ¨æ¶æ„ï¼Œå¢å¼ºäº†ç‰¹å¾æå–èƒ½åŠ›ï¼Œå¯å®ç°æ›´ç²¾ç¡®çš„å¯¹è±¡æ£€æµ‹å’Œå¤æ‚ä»»åŠ¡æ€§èƒ½ã€‚
  * é’ˆå¯¹æ•ˆç‡å’Œé€Ÿåº¦è¿›è¡Œäº†ä¼˜åŒ–ï¼šYOLO11 å¼•å…¥äº†å®Œå–„çš„æ¶æ„è®¾è®¡å’Œä¼˜åŒ–çš„è®­ç»ƒæµç¨‹ï¼Œå¯æä¾›æ›´å¿«çš„å¤„ç†é€Ÿåº¦ï¼Œå¹¶åœ¨å‡†ç¡®åº¦å’Œæ€§èƒ½ä¹‹é—´ä¿æŒæœ€ä½³å¹³è¡¡ã€‚
  * æ›´å°‘çš„å‚æ•°ï¼Œæ›´é«˜çš„å‡†ç¡®åº¦ï¼šå€ŸåŠ©æ¨¡å‹è®¾è®¡çš„è¿›æ­¥ï¼ŒYOLO11m åœ¨ COCO æ•°æ®é›†ä¸Šå®ç°äº†æ›´é«˜çš„å¹³å‡å‡†ç¡®åº¦ (mAP)ï¼ŒåŒæ—¶ä½¿ç”¨çš„å‚æ•°æ¯” YOLOv8m å°‘ 22%ï¼Œä»è€Œæé«˜äº†è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶åˆä¸å½±å“å‡†ç¡®åº¦ã€‚
  * è·¨ç¯å¢ƒçš„é€‚åº”æ€§ï¼šYOLO11 å¯ä»¥æ— ç¼éƒ¨ç½²åœ¨å„ç§ç¯å¢ƒä¸­ï¼ŒåŒ…æ‹¬è¾¹ç¼˜è®¾å¤‡ã€äº‘å¹³å°å’Œæ”¯æŒ NVIDIA GPU çš„ç³»ç»Ÿï¼Œä»è€Œç¡®ä¿æœ€å¤§çš„çµæ´»æ€§ã€‚
  * æ”¯æŒçš„ä»»åŠ¡èŒƒå›´å¹¿æ³›ï¼šæ— è®ºæ˜¯å¯¹è±¡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€å›¾åƒåˆ†ç±»ã€å§¿åŠ¿ä¼°è®¡è¿˜æ˜¯å®šå‘å¯¹è±¡æ£€æµ‹ (OBB)ï¼ŒYOLO11 éƒ½æ—¨åœ¨æ»¡è¶³å„ç§è®¡ç®—æœºè§†è§‰æŒ‘æˆ˜ã€‚

##### æ”¯æŒçš„ä»»åŠ¡å’Œæ¨¡å¼

YOLO11 ä»¥ YOLOv8 ä¸­å¼•å…¥çš„å¤šåŠŸèƒ½æ¨¡å‹ç³»åˆ—ä¸ºåŸºç¡€ï¼Œä¸ºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡æä¾›å¢å¼ºçš„æ”¯æŒï¼š

Model| Filenames| Task| Inference| Validation| Training| Export  
---|---|---|---|---|---|---  
YOLO11| yolol11n.pt, yolol11s.pt, yolol11m.pt, yolol11x.pt| Detection| âœ…| âœ…|
âœ…| âœ…  
YOLO11-seg| yolol11n-seg.pt, yolol11s-seg.pt, yolol11m-seg.pt,
yolol11x-seg.pt| Instance Segmentation| âœ…| âœ…| âœ…| âœ…  
YOLO11-pose| yolol11n-pose.pt, yolol11s-pose.pt, yolol11m-pose.pt,
yolol11x-pose.pt| Pose/Keypoints| âœ…| âœ…| âœ…| âœ…  
YOLO11-obb| yolol11n-obb.pt, yolol11s-obb.pt, yolol11m-obb.pt,
yolol11x-obb.pt| Oriented Detection| âœ…| âœ…| âœ…| âœ…  
YOLO11-cls| yolol11n-cls.pt, yolol11s-cls.pt, yolol11m-cls.pt,
yolol11x-cls.pt| Classification| âœ…| âœ…| âœ…| âœ…  
  
##### ç®€å•çš„ YOLO11 è®­ç»ƒå’Œæ¨ç†ç¤ºä¾‹

ä»¥ä¸‹ç¤ºä¾‹é€‚ç”¨äºç”¨äºå¯¹è±¡æ£€æµ‹çš„ YOLO11 Detect æ¨¡å‹ã€‚

    
    
    from ultralytics import YOLO
    
    # Load a model
    model = YOLO("yolo11n.pt")
    
    # Train the model
    train_results = model.train(
        data="coco8.yaml",  # path to dataset YAML
        epochs=100,  # number of training epochs
        imgsz=640,  # training image size
        device="cpu",  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu
    )
    
    # Evaluate model performance on the validation set
    metrics = model.val()
    
    # Perform object detection on an image
    results = model("path/to/image.jpg")
    results[0].show()
    
    # Export the model to ONNX format
    path = model.export(format="onnx")  # return path to exported model

##### æ”¯æŒéƒ¨ç½²äºè¾¹ç¼˜è®¾å¤‡

YOLO11 ä¸“ä¸ºé€‚åº”å„ç§ç¯å¢ƒè€Œè®¾è®¡ï¼ŒåŒ…æ‹¬è¾¹ç¼˜è®¾å¤‡ã€‚å…¶ä¼˜åŒ–çš„æ¶æ„å’Œé«˜æ•ˆçš„å¤„ç†èƒ½åŠ›ä½¿å…¶é€‚åˆéƒ¨ç½²åœ¨è¾¹ç¼˜è®¾å¤‡ã€äº‘å¹³å°å’Œæ”¯æŒ NVIDIA GPU
çš„ç³»ç»Ÿä¸Šã€‚è¿™ç§çµæ´»æ€§ç¡®ä¿ YOLO11 å¯ç”¨äºå„ç§åº”ç”¨ï¼Œä»ç§»åŠ¨è®¾å¤‡ä¸Šçš„å®æ—¶æ£€æµ‹åˆ°äº‘ç¯å¢ƒä¸­çš„å¤æ‚åˆ†å‰²ä»»åŠ¡ã€‚æœ‰å…³éƒ¨ç½²é€‰é¡¹çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…å¯¼å‡ºæ–‡æ¡£ã€‚

##### YOLOv11 yamlæ–‡ä»¶

    
    
    # Ultralytics YOLO ğŸš€, AGPL-3.0 license
    # YOLO11 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect
    
    # Parameters
    nc: 80 # number of classes
    scales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n'
      # [depth, width, max_channels]
      n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs
      s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs
      m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs
      l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs
      x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs
    
    # YOLO11n backbone
    backbone:
      # [from, repeats, module, args]
      - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
      - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
      - [-1, 2, C3k2, [256, False, 0.25]]
      - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
      - [-1, 2, C3k2, [512, False, 0.25]]
      - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
      - [-1, 2, C3k2, [512, True]]
      - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
      - [-1, 2, C3k2, [1024, True]]
      - [-1, 1, SPPF, [1024, 5]] # 9
      - [-1, 2, C2PSA, [1024]] # 10
    
    # YOLO11n head
    head:
      - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
      - [[-1, 6], 1, Concat, [1]] # cat backbone P4
      - [-1, 2, C3k2, [512, False]] # 13
    
      - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
      - [[-1, 4], 1, Concat, [1]] # cat backbone P3
      - [-1, 2, C3k2, [256, False]] # 16 (P3/8-small)
    
      - [-1, 1, Conv, [256, 3, 2]]
      - [[-1, 13], 1, Concat, [1]] # cat head P4
      - [-1, 2, C3k2, [512, False]] # 19 (P4/16-medium)
    
      - [-1, 1, Conv, [512, 3, 2]]
      - [[-1, 10], 1, Concat, [1]] # cat head P5
      - [-1, 2, C3k2, [1024, True]] # 22 (P5/32-large)
    
      - [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)
    

**YOLO11å’ŒYOLOv8 yamlæ–‡ä»¶çš„åŒºåˆ«**

![](https://i-blog.csdnimg.cn/direct/a8f3766a015c4ad2a49411ab710b3477.png)

##### æ”¹è¿›æ¨¡å—ä»£ç 

  * C3k2 

    
    
    class C3k2(C2f):
        """Faster Implementation of CSP Bottleneck with 2 convolutions."""
    
        def __init__(self, c1, c2, n=1, c3k=False, e=0.5, g=1, shortcut=True):
            """Initializes the C3k2 module, a faster CSP Bottleneck with 2 convolutions and optional C3k blocks."""
            super().__init__(c1, c2, n, shortcut, g, e)
            self.m = nn.ModuleList(
                C3k(self.c, self.c, 2, shortcut, g) if c3k else Bottleneck(self.c, self.c, shortcut, g) for _ in range(n)
            )

C3k2ï¼Œå®ƒæ˜¯å…·æœ‰ä¸¤ä¸ªå·ç§¯çš„CSPï¼ˆPartial Cross Stageï¼‰ç“¶é¢ˆæ¶æ„çš„æ›´å¿«å®ç°ã€‚

**ç±»ç»§æ‰¿ï¼š**

  * `C3k2`ç»§æ‰¿è‡ªç±»`C2f`ã€‚è¿™è¡¨æ˜`C2f`å¾ˆå¯èƒ½å®ç°äº†ç»è¿‡ä¿®æ”¹çš„åŸºæœ¬CSPç»“æ„ï¼Œè€Œ`C3k2`è¿›ä¸€æ­¥ä¼˜åŒ–æˆ–ä¿®æ”¹äº†æ­¤ç»“æ„ã€‚

**æ„é€ å‡½æ•°ï¼ˆ`__init__`ï¼‰ï¼š**

  * `c1`ï¼šè¾“å…¥é€šé“ã€‚

  * `c2`ï¼šè¾“å‡ºé€šé“ã€‚

  * `n`ï¼šç“¶é¢ˆå±‚æ•°ï¼ˆé»˜è®¤ä¸º1ï¼‰ã€‚

  * `c3k`ï¼šä¸€ä¸ªå¸ƒå°”æ ‡å¿—ï¼Œç¡®å®šæ˜¯å¦ä½¿ç”¨`C3k`å—æˆ–å¸¸è§„`Bottleneck`å—ã€‚

  * `e`ï¼šæ‰©å±•æ¯”ç‡ï¼Œæ§åˆ¶éšè—å±‚çš„å®½åº¦ï¼ˆé»˜è®¤ä¸º0.5ï¼‰ã€‚

  * `g`ï¼šåˆ†ç»„å·ç§¯çš„ç»„å½’ä¸€åŒ–å‚æ•°æˆ–ç»„æ•°ï¼ˆé»˜è®¤å€¼ä¸º 1ï¼‰ã€‚

  * `shortcut`ï¼šä¸€ä¸ªå¸ƒå°”å€¼ï¼Œç”¨äºç¡®å®šæ˜¯å¦åœ¨ç½‘ç»œä¸­åŒ…å«å¿«æ·æ–¹å¼è¿æ¥ï¼ˆé»˜è®¤å€¼ä¸º `True`ï¼‰ã€‚

**åˆå§‹åŒ–ï¼š**

  * `super().__init__(c1, c2, n, short-cut, g, e)` è°ƒç”¨çˆ¶ç±» `C2f` çš„æ„é€ å‡½æ•°ï¼Œåˆå§‹åŒ–æ ‡å‡† CSP ç»„ä»¶ï¼Œå¦‚é€šé“æ•°ã€å¿«æ·æ–¹å¼ã€ç»„ç­‰ã€‚

**æ¨¡å—åˆ—è¡¨ï¼ˆ`self.m`ï¼‰ï¼š**

  * `nn.ModuleList` å­˜å‚¨ `C3k` æˆ– `Bottleneck` æ¨¡å—ï¼Œå…·ä½“å–å†³äº `c3k` çš„å€¼ã€‚

  * å¦‚æœ `c3k` ä¸º `True`ï¼Œå®ƒä¼šåˆå§‹åŒ– `C3k` æ¨¡å—ã€‚`C3k` æ¨¡å—æ¥æ”¶ä»¥ä¸‹å‚æ•°ï¼š

  * `self.c`ï¼šé€šé“æ•°ï¼ˆæºè‡ª `C2f`ï¼‰ã€‚

  * `2`ï¼šè¿™è¡¨ç¤ºåœ¨ `C3k` å—å†…ä½¿ç”¨äº†ä¸¤ä¸ªå·ç§¯å±‚ã€‚

  * `shortcut` å’Œ `g`ï¼šä» `C3k2` æ„é€ å‡½æ•°ä¼ é€’ã€‚

  * å¦‚æœ `c3k` ä¸º `False`ï¼Œåˆ™åˆå§‹åŒ–æ ‡å‡† `Bottleneck` æ¨¡å—ã€‚

`for _ in range(n)` è¡¨ç¤ºå°†åˆ›å»º `n` ä¸ªè¿™æ ·çš„å—ã€‚

**æ€»ç»“ï¼š**

  * `C3k2` å®ç°äº† CSP ç“¶é¢ˆæ¶æ„ï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨è‡ªå®šä¹‰ `C3k` å—ï¼ˆå…·æœ‰ä¸¤ä¸ªå·ç§¯ï¼‰æˆ–æ ‡å‡† `Bottleneck` å—ï¼Œå…·ä½“å–å†³äº `c3k` æ ‡å¿—ã€‚

  * C2PSA

    
    
    class C2PSA(nn.Module):
        """
        C2PSA module with attention mechanism for enhanced feature extraction and processing.
    
        This module implements a convolutional block with attention mechanisms to enhance feature extraction and processing
        capabilities. It includes a series of PSABlock modules for self-attention and feed-forward operations.
    
        Attributes:
            c (int): Number of hidden channels.
            cv1 (Conv): 1x1 convolution layer to reduce the number of input channels to 2*c.
            cv2 (Conv): 1x1 convolution layer to reduce the number of output channels to c.
            m (nn.Sequential): Sequential container of PSABlock modules for attention and feed-forward operations.
    
        Methods:
            forward: Performs a forward pass through the C2PSA module, applying attention and feed-forward operations.
    
        Notes:
            This module essentially is the same as PSA module, but refactored to allow stacking more PSABlock modules.
    
        Examples:
            >>> c2psa = C2PSA(c1=256, c2=256, n=3, e=0.5)
            >>> input_tensor = torch.randn(1, 256, 64, 64)
            >>> output_tensor = c2psa(input_tensor)
        """
    
        def __init__(self, c1, c2, n=1, e=0.5):
            """Initializes the C2PSA module with specified input/output channels, number of layers, and expansion ratio."""
            super().__init__()
            assert c1 == c2
            self.c = int(c1 * e)
            self.cv1 = Conv(c1, 2 * self.c, 1, 1)
            self.cv2 = Conv(2 * self.c, c1, 1)
    
            self.m = nn.Sequential(*(PSABlock(self.c, attn_ratio=0.5, num_heads=self.c // 64) for _ in range(n)))
    
        def forward(self, x):
            """Processes the input tensor 'x' through a series of PSA blocks and returns the transformed tensor."""
            a, b = self.cv1(x).split((self.c, self.c), dim=1)
            b = self.m(b)
            return self.cv2(torch.cat((a, b), 1))

`C2PSA` æ¨¡å—æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰ç¥ç»ç½‘ç»œå±‚ï¼Œå¸¦æœ‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºå¢å¼ºç‰¹å¾æå–å’Œå¤„ç†ã€‚

**ç±»æ¦‚è¿°**

  * **ç›®çš„ï¼š**

  * `C2PSA` æ¨¡å—å¼•å…¥äº†ä¸€ä¸ªå·ç§¯å—ï¼Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥æ”¹è¿›ç‰¹å¾æå–å’Œå¤„ç†ã€‚

  * å®ƒä½¿ç”¨ä¸€ç³»åˆ— `PSABlock` æ¨¡å—ï¼Œè¿™äº›æ¨¡å—å¯èƒ½ä»£è¡¨æŸç§å½¢å¼çš„ä½ç½®è‡ªæ³¨æ„åŠ› (PSA)ï¼Œå¹¶ä¸”è¯¥æ¶æ„æ—¨åœ¨å…è®¸å †å å¤šä¸ª `PSABlock` å±‚ã€‚

**æ„é€ å‡½æ•°ï¼ˆ`__init__`ï¼‰ï¼š**

  * **å‚æ•°ï¼š**

  * `c1`ï¼šè¾“å…¥é€šé“ï¼ˆå¿…é¡»ç­‰äº `c2`ï¼‰ã€‚

  * `c2`ï¼šè¾“å‡ºé€šé“ï¼ˆå¿…é¡»ç­‰äº `c1`ï¼‰ã€‚

  * `n`ï¼šè¦å †å çš„ `PSABlock` æ¨¡å—æ•°é‡ï¼ˆé»˜è®¤å€¼ä¸º 1ï¼‰ã€‚

  * `e`ï¼šæ‰©å±•æ¯”ç‡ï¼Œç”¨äºè®¡ç®—éšè—é€šé“çš„æ•°é‡ï¼ˆé»˜è®¤å€¼ä¸º 0.5ï¼‰ã€‚

  * **å±æ€§ï¼š**

  * `self.c`ï¼šéšè—é€šé“æ•°ï¼Œè®¡ç®—ä¸º `int(c1 * e)`ã€‚

  * `self.cv1`ï¼šä¸€ä¸ª `1x1` å·ç§¯ï¼Œå°†è¾“å…¥é€šé“æ•°ä» `c1` å‡å°‘åˆ° `2 * self.c`ã€‚è¿™ä¸ºå°†è¾“å…¥åˆ†æˆä¸¤éƒ¨åˆ†åšå¥½å‡†å¤‡ã€‚

  * `self.cv2`ï¼šå¦ä¸€ä¸ª `1x1` å·ç§¯ï¼Œå¤„ç†åå°†é€šé“ç»´åº¦æ¢å¤å› `c1`ã€‚

  * `self.m`ï¼šä¸€ç³»åˆ— `PSABlock` æ¨¡å—ã€‚æ¯ä¸ª `PSABlock` æ¥æ”¶ `self.c` é€šé“ï¼Œæ³¨æ„å¤´çš„æ•°é‡ä¸º `self.c // 64`ã€‚æ¯ä¸ªå—åº”ç”¨æ³¨æ„å’Œå‰é¦ˆæ“ä½œã€‚

**å‰å‘æ–¹æ³•ï¼š**

  * **è¾“å…¥ï¼š**

  * `x`ï¼Œè¾“å…¥å¼ é‡ã€‚

  * **æ“ä½œï¼š**

  1. `self.cv1(x)` åº”ç”¨ `1x1` å·ç§¯ï¼Œå°†è¾“å…¥é€šé“å¤§å°ä» `c1` å‡å°åˆ° `2 * self.c`ã€‚

  2. ç”Ÿæˆçš„å¼ é‡æ²¿é€šé“ç»´åº¦åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œ`a` å’Œ `b`ã€‚

  * `a`ï¼šç¬¬ä¸€ä¸ª `self.c` é€šé“ã€‚

  * `b`ï¼šå‰©ä½™çš„ `self.c` é€šé“ã€‚

  1. `b` é€šè¿‡é¡ºåºå®¹å™¨ `self.m`ï¼Œå®ƒæ˜¯ `PSABlock` æ¨¡å—çš„å †æ ˆã€‚è¿™éƒ¨åˆ†ç»è¿‡åŸºäºæ³¨æ„çš„å¤„ç†ã€‚

  2. å¤„ç†åçš„å¼ é‡ `b` ä¸ `a` è¿æ¥ã€‚

  3. `self.cv2` åº”ç”¨ `1x1` å·ç§¯ï¼Œå°†é€šé“å¤§å°æ¢å¤ä¸º `c1`ã€‚

  * **è¾“å‡ºï¼š**

  * åº”ç”¨æ³¨æ„å’Œå·ç§¯æ“ä½œåçš„å˜æ¢åçš„å¼ é‡ã€‚

**æ€»ç»“ï¼š**

  * **C2PSA** æ˜¯ä¸€ä¸ªå¢å¼ºå‹å·ç§¯æ¨¡å—ï¼Œå®ƒé€šè¿‡å †å çš„ `PSABlock` æ¨¡å—åº”ç”¨ä½ç½®è‡ªæ³¨æ„åŠ›ã€‚å®ƒæ‹†åˆ†è¾“å…¥å¼ é‡ï¼Œå°†æ³¨æ„åŠ›åº”ç”¨äºå…¶ä¸­ä¸€éƒ¨åˆ†ï¼Œç„¶åé‡æ–°ç»„åˆå¹¶é€šè¿‡æœ€ç»ˆå·ç§¯å¯¹å…¶è¿›è¡Œå¤„ç†ã€‚æ­¤ç»“æ„æœ‰åŠ©äºä»è¾“å…¥æ•°æ®ä¸­æå–å¤æ‚ç‰¹å¾ã€‚

##### ç½‘ç»œç»“æ„

![](https://i-blog.csdnimg.cn/direct/761af09befeb45adafae36b679424b26.png)

![](https://i-blog.csdnimg.cn/direct/45e481e295ad458fa7fe4c252fbd5d83.png)




### 8.200+ç§å…¨å¥—æ”¹è¿›YOLOV11åˆ›æ–°ç‚¹åŸç†è®²è§£

#### 8.1 200+ç§å…¨å¥—æ”¹è¿›YOLOV11åˆ›æ–°ç‚¹åŸç†è®²è§£å¤§å…¨

ç”±äºç¯‡å¹…é™åˆ¶ï¼Œæ¯ä¸ªåˆ›æ–°ç‚¹çš„å…·ä½“åŸç†è®²è§£å°±ä¸å…¨éƒ¨å±•å¼€ï¼Œå…·ä½“è§ä¸‹åˆ—ç½‘å€ä¸­çš„æ”¹è¿›æ¨¡å—å¯¹åº”é¡¹ç›®çš„æŠ€æœ¯åŸç†åšå®¢ç½‘å€ã€Blogã€‘ï¼ˆåˆ›æ–°ç‚¹å‡ä¸ºæ¨¡å—åŒ–æ­å»ºï¼ŒåŸç†é€‚é…YOLOv5~YOLOv11ç­‰å„ç§ç‰ˆæœ¬ï¼‰

[æ”¹è¿›æ¨¡å—æŠ€æœ¯åŸç†åšå®¢ã€Blogã€‘ç½‘å€é“¾æ¥](https://gitee.com/qunmasj/good)

![9.png](9.png)

#### 8.2 ç²¾é€‰éƒ¨åˆ†æ”¹è¿›YOLOV11åˆ›æ–°ç‚¹åŸç†è®²è§£

###### è¿™é‡ŒèŠ‚é€‰éƒ¨åˆ†æ”¹è¿›åˆ›æ–°ç‚¹å±•å¼€åŸç†è®²è§£(å®Œæ•´çš„æ”¹è¿›åŸç†è§ä¸Šå›¾å’Œ[æ”¹è¿›æ¨¡å—æŠ€æœ¯åŸç†åšå®¢é“¾æ¥](https://gitee.com/qunmasj/good)ã€å¦‚æœæ­¤å°èŠ‚çš„å›¾åŠ è½½å¤±è´¥å¯ä»¥é€šè¿‡CSDNæˆ–è€…Githubæœç´¢è¯¥åšå®¢çš„æ ‡é¢˜è®¿é—®åŸå§‹åšå®¢ï¼ŒåŸå§‹åšå®¢å›¾ç‰‡æ˜¾ç¤ºæ­£å¸¸ã€‘
ï»¿

### ç©ºé—´å’Œé€šé“é‡å»ºå·ç§¯SCConv
å‚è€ƒè¯¥åšå®¢æå‡ºçš„ä¸€ç§é«˜æ•ˆçš„å·ç§¯æ¨¡å—ï¼Œç§°ä¸ºSCConv (spatial and channel reconstruction convolution)ï¼Œä»¥å‡å°‘å†—ä½™è®¡ç®—å¹¶ä¿ƒè¿›ä»£è¡¨æ€§ç‰¹å¾çš„å­¦ä¹ ã€‚æå‡ºçš„SCConvç”±ç©ºé—´é‡æ„å•å…ƒ(SRU)å’Œä¿¡é“é‡æ„å•å…ƒ(CRU)ä¸¤ä¸ªå•å…ƒç»„æˆã€‚

ï¼ˆ1ï¼‰SRUæ ¹æ®æƒé‡åˆ†ç¦»å†—ä½™ç‰¹å¾å¹¶è¿›è¡Œé‡æ„ï¼Œä»¥æŠ‘åˆ¶ç©ºé—´ç»´åº¦ä¸Šçš„å†—ä½™ï¼Œå¢å¼ºç‰¹å¾çš„è¡¨å¾ã€‚

ï¼ˆ2ï¼‰CRUé‡‡ç”¨åˆ†è£‚å˜æ¢å’Œèåˆç­–ç•¥æ¥å‡å°‘ä¿¡é“ç»´åº¦çš„å†—ä½™ä»¥åŠè®¡ç®—æˆæœ¬å’Œå­˜å‚¨ã€‚

ï¼ˆ3ï¼‰SCConvæ˜¯ä¸€ç§å³æ’å³ç”¨çš„æ¶æ„å•å…ƒï¼Œå¯ç›´æ¥ç”¨äºæ›¿ä»£å„ç§å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„æ ‡å‡†å·ç§¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒscconvoåµŒå…¥æ¨¡å‹èƒ½å¤Ÿé€šè¿‡å‡å°‘å†—ä½™ç‰¹å¾æ¥è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”æ˜¾è‘—é™ä½äº†å¤æ‚åº¦å’Œè®¡ç®—æˆæœ¬ã€‚



SCConvå¦‚å›¾æ‰€ç¤ºï¼Œå®ƒç”±ä¸¤ä¸ªå•å…ƒç»„æˆï¼Œç©ºé—´é‡å»ºå•å…ƒ(SRU)å’Œé€šé“é‡å»ºå•å…ƒ(CRU)ï¼Œä»¥é¡ºåºçš„æ–¹å¼æ”¾ç½®ã€‚å…·ä½“è€Œè¨€ï¼Œå¯¹äºç“¶é¢ˆæ®‹å·®å—ä¸­çš„ä¸­é—´è¾“å…¥ç‰¹å¾Xï¼Œé¦–å…ˆé€šè¿‡SRUè¿ç®—è·å¾—ç©ºé—´ç»†åŒ–ç‰¹å¾Xwï¼Œç„¶ååˆ©ç”¨CRUè¿ç®—è·å¾—ä¿¡é“ç»†åŒ–ç‰¹å¾Yã€‚SCConvæ¨¡å—å……åˆ†åˆ©ç”¨äº†ç‰¹å¾ä¹‹é—´çš„ç©ºé—´å†—ä½™å’Œé€šé“å†—ä½™ï¼Œå¯ä»¥æ— ç¼é›†æˆåˆ°ä»»ä½•CNNæ¶æ„ä¸­ï¼Œä»¥å‡å°‘ä¸­é—´ç‰¹å¾æ˜ å°„ä¹‹é—´çš„å†—ä½™å¹¶å¢å¼ºCNNçš„ç‰¹å¾è¡¨ç¤ºã€‚

#### SRUå•å…ƒç”¨äºç©ºé—´å†—ä½™



ä¸ºäº†åˆ©ç”¨ç‰¹å¾çš„ç©ºé—´å†—ä½™ï¼Œå¼•å…¥äº†ç©ºé—´é‡æ„å•å…ƒ(SRU)ï¼Œå¦‚å›¾2æ‰€ç¤ºï¼Œå®ƒåˆ©ç”¨äº†åˆ†ç¦»å’Œé‡æ„æ“ä½œã€‚

åˆ†ç¦»æ“ä½œ çš„ç›®çš„æ˜¯å°†ä¿¡æ¯ä¸°å¯Œçš„ç‰¹å¾å›¾ä¸ç©ºé—´å†…å®¹å¯¹åº”çš„ä¿¡æ¯è¾ƒå°‘çš„ç‰¹å¾å›¾åˆ†ç¦»å¼€æ¥ã€‚æˆ‘ä»¬åˆ©ç”¨ç»„å½’ä¸€åŒ–(GN)å±‚ä¸­çš„æ¯”ä¾‹å› å­æ¥è¯„ä¼°ä¸åŒç‰¹å¾å›¾çš„ä¿¡æ¯å†…å®¹ã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€ä¸ªä¸­é—´ç‰¹å¾æ˜ å°„XâˆˆR NÃ—CÃ—HÃ—Wï¼Œé¦–å…ˆé€šè¿‡å‡å»å¹³å‡å€¼Âµå¹¶é™¤ä»¥æ ‡å‡†å·®Ïƒæ¥æ ‡å‡†åŒ–è¾“å…¥ç‰¹å¾Xï¼Œå¦‚ä¸‹æ‰€ç¤º:

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/6376a4da82e14689bee26dee3932f6af.png)


å…¶ä¸­Âµå’ŒÏƒæ˜¯Xçš„å‡å€¼å’Œæ ‡å‡†å·®ï¼ŒÎµæ˜¯ä¸ºäº†é™¤æ³•ç¨³å®šæ€§è€ŒåŠ å…¥çš„ä¸€ä¸ªå°çš„æ­£å¸¸æ•°ï¼ŒÎ³å’ŒÎ²æ˜¯å¯è®­ç»ƒçš„ä»¿å°„å˜æ¢ã€‚

GNå±‚ä¸­çš„å¯è®­ç»ƒå‚æ•°\gamma \in R^{C}ç”¨äºæµ‹é‡æ¯ä¸ªæ‰¹æ¬¡å’Œé€šé“çš„ç©ºé—´åƒç´ æ–¹å·®ã€‚æ›´ä¸°å¯Œçš„ç©ºé—´ä¿¡æ¯åæ˜ äº†ç©ºé—´åƒç´ çš„æ›´å¤šå˜åŒ–ï¼Œä»è€Œå¯¼è‡´æ›´å¤§çš„Î³ã€‚å½’ä¸€åŒ–ç›¸å…³æƒé‡W_{\gamma} \in R^{C}ç”±ä¸‹é¢å…¬å¼2å¾—åˆ°ï¼Œè¡¨ç¤ºä¸åŒç‰¹å¾æ˜ å°„çš„é‡è¦æ€§ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/df6c6f4914344b16b6e8663d929d5100.png)


ç„¶åå°†ç»WÎ³é‡æ–°åŠ æƒçš„ç‰¹å¾æ˜ å°„çš„æƒå€¼é€šè¿‡sigmoidå‡½æ•°æ˜ å°„åˆ°(0,1)èŒƒå›´ï¼Œå¹¶é€šè¿‡é˜ˆå€¼è¿›è¡Œé—¨æ§ã€‚æˆ‘ä»¬å°†é˜ˆå€¼ä»¥ä¸Šçš„æƒé‡è®¾ç½®ä¸º1ï¼Œå¾—åˆ°ä¿¡æ¯æƒé‡W1ï¼Œå°†å…¶è®¾ç½®ä¸º0ï¼Œå¾—åˆ°éä¿¡æ¯æƒé‡W2(å®éªŒä¸­é˜ˆå€¼è®¾ç½®ä¸º0.5)ã€‚è·å–Wçš„æ•´ä¸ªè¿‡ç¨‹å¯ä»¥ç”¨å…¬å¼è¡¨ç¤ºã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/8a1fc6342ff3446ea1700c976947d6c1.png)


æœ€åå°†è¾“å…¥ç‰¹å¾Xåˆ†åˆ«ä¹˜ä»¥W1å’ŒW2ï¼Œå¾—åˆ°ä¸¤ä¸ªåŠ æƒç‰¹å¾:ä¿¡æ¯é‡è¾ƒå¤§çš„ç‰¹å¾X_{1}^{\omega }å’Œä¿¡æ¯é‡è¾ƒå°çš„ç‰¹å¾X_{2}^{\omega }ã€‚è¿™æ ·å°±æˆåŠŸåœ°å°†è¾“å…¥ç‰¹å¾åˆ†ä¸ºä¸¤éƒ¨åˆ†:X_{1}^{\omega }å…·æœ‰ä¿¡æ¯é‡å’Œè¡¨è¾¾æ€§çš„ç©ºé—´å†…å®¹ï¼Œè€ŒX_{2}^{\omega }å‡ ä¹æ²¡æœ‰ä¿¡æ¯ï¼Œè¢«è®¤ä¸ºæ˜¯å†—ä½™çš„ã€‚

é‡æ„æ“ä½œ å°†ä¿¡æ¯ä¸°å¯Œçš„ç‰¹å¾ä¸ä¿¡æ¯è¾ƒå°‘çš„ç‰¹å¾ç›¸åŠ ï¼Œç”Ÿæˆä¿¡æ¯æ›´ä¸°å¯Œçš„ç‰¹å¾ï¼Œä»è€ŒèŠ‚çœç©ºé—´ç©ºé—´ã€‚é‡‡ç”¨äº¤å‰é‡æ„è¿ç®—ï¼Œå°†åŠ æƒåçš„ä¸¤ä¸ªä¸åŒçš„ä¿¡æ¯ç‰¹å¾å……åˆ†ç»“åˆèµ·æ¥ï¼ŒåŠ å¼ºå®ƒä»¬ä¹‹é—´çš„ä¿¡æ¯æµã€‚ç„¶åå°†äº¤å‰é‡æ„çš„ç‰¹å¾X^{\omega1}å’ŒX^{\omega2}è¿›è¡Œæ‹¼æ¥ï¼Œå¾—åˆ°ç©ºé—´ç²¾ç»†ç‰¹å¾æ˜ å°„X^{\omega}ã€‚ä»åè¿‡ç¨‹è¡¨ç¤ºå¦‚ä¸‹ï¼š

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/454d12b8e9a3415696ed0c958cf106d3.png)


å…¶ä¸­âŠ—æ˜¯é€å…ƒç´ çš„ä¹˜æ³•ï¼ŒâŠ•æ˜¯é€å…ƒç´ çš„æ±‚å’Œï¼Œâˆªæ˜¯ä¸²è”ã€‚å°†SRUåº”ç”¨äºä¸­é—´è¾“å…¥ç‰¹å¾Xåï¼Œä¸ä»…å°†ä¿¡æ¯ç‰¹å¾ä¸ä¿¡æ¯è¾ƒå°‘çš„ç‰¹å¾åˆ†ç¦»ï¼Œè€Œä¸”å¯¹å…¶è¿›è¡Œé‡æ„ï¼Œå¢å¼ºä»£è¡¨æ€§ç‰¹å¾ï¼ŒæŠ‘åˆ¶ç©ºé—´ç»´åº¦ä¸Šçš„å†—ä½™ç‰¹å¾ã€‚ç„¶è€Œï¼Œç©ºé—´ç²¾ç»†ç‰¹å¾æ˜ å°„X^{\omega}åœ¨é€šé“ç»´åº¦ä¸Šä»ç„¶æ˜¯å†—ä½™çš„ã€‚

#### CRUå•å…ƒç”¨äºé€šé“å†—ä½™
![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/direct/f3741f6c506c45cc929d7e906226b2e3.png)



åˆ†å‰² æ“ä½œå°†è¾“å…¥çš„ç©ºé—´ç»†åŒ–ç‰¹å¾X^{\omega}åˆ†å‰²æˆä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†é€šé“æ•°æ˜¯\alpha Cï¼Œå¦ä¸€éƒ¨åˆ†é€šé“æ•°æ˜¯(1-\alpha) Cï¼Œéšåå¯¹ä¸¤ç»„ç‰¹å¾çš„é€šé“æ•°ä½¿ç”¨1 * 1å·ç§¯æ ¸è¿›è¡Œå‹ç¼©ï¼Œåˆ†åˆ«å¾—åˆ°X_{up}å’ŒX_{low}ã€‚

è½¬æ¢ æ“ä½œå°†è¾“å…¥çš„X_{up}ä½œä¸ºâ€œå¯Œç‰¹å¾æå–â€çš„è¾“å…¥ï¼Œåˆ†åˆ«è¿›è¡ŒGWCå’ŒPWCï¼Œç„¶åç›¸åŠ å¾—åˆ°è¾“å‡ºY1ï¼Œå°†è¾“å…¥X_{low}ä½œä¸ºâ€œå¯Œç‰¹å¾æå–â€çš„è¡¥å……ï¼Œè¿›è¡ŒPWCï¼Œå¾—åˆ°çš„è®°è¿‡å’ŒåŸæ¥çš„è¾“å…¥å–å¹¶é›†å¾—åˆ°Y2ã€‚

èåˆ æ“ä½œä½¿ç”¨ç®€åŒ–çš„SKNetæ–¹æ³•æ¥è‡ªé€‚åº”åˆå¹¶Y1å’ŒY2ã€‚å…·ä½“è¯´æ˜¯é¦–å…ˆä½¿ç”¨å…¨å±€å¹³å‡æ± åŒ–å°†å…¨å±€ç©ºé—´ä¿¡æ¯å’Œé€šé“ç»Ÿè®¡ä¿¡æ¯ç»“åˆèµ·æ¥ï¼Œå¾—åˆ°ç»è¿‡æ± åŒ–çš„S1å’ŒS2ã€‚ç„¶åå¯¹S1å’ŒS2åšSoftmaxå¾—åˆ°ç‰¹å¾æƒé‡å‘é‡\beta _{1}å’Œ\beta _{2}ï¼Œæœ€åä½¿ç”¨ç‰¹å¾æƒé‡å‘é‡å¾—åˆ°è¾“å‡ºY = \beta _{1}*Y_{1} + \beta _{2}*Y_{2}ï¼ŒYå³ä¸ºé€šé“æç‚¼çš„ç‰¹å¾ã€‚


### 9.ç³»ç»ŸåŠŸèƒ½å±•ç¤º

å›¾9.1.ç³»ç»Ÿæ”¯æŒæ£€æµ‹ç»“æœè¡¨æ ¼æ˜¾ç¤º

  å›¾9.2.ç³»ç»Ÿæ”¯æŒç½®ä¿¡åº¦å’ŒIOUé˜ˆå€¼æ‰‹åŠ¨è°ƒèŠ‚

  å›¾9.3.ç³»ç»Ÿæ”¯æŒè‡ªå®šä¹‰åŠ è½½æƒé‡æ–‡ä»¶best.pt(éœ€è¦ä½ é€šè¿‡æ­¥éª¤5ä¸­è®­ç»ƒè·å¾—)

  å›¾9.4.ç³»ç»Ÿæ”¯æŒæ‘„åƒå¤´å®æ—¶è¯†åˆ«

  å›¾9.5.ç³»ç»Ÿæ”¯æŒå›¾ç‰‡è¯†åˆ«

  å›¾9.6.ç³»ç»Ÿæ”¯æŒè§†é¢‘è¯†åˆ«

  å›¾9.7.ç³»ç»Ÿæ”¯æŒè¯†åˆ«ç»“æœæ–‡ä»¶è‡ªåŠ¨ä¿å­˜

  å›¾9.8.ç³»ç»Ÿæ”¯æŒExcelå¯¼å‡ºæ£€æµ‹ç»“æœæ•°æ®

![10.png](10.png)

![11.png](11.png)

![12.png](12.png)

![13.png](13.png)

![14.png](14.png)

![15.png](15.png)

![16.png](16.png)

![17.png](17.png)

### 10. YOLOv11æ ¸å¿ƒæ”¹è¿›æºç è®²è§£

#### 10.1 VanillaNet.py

ä»¥ä¸‹æ˜¯å¯¹ä»£ç çš„æ ¸å¿ƒéƒ¨åˆ†è¿›è¡Œæç‚¼å’Œè¯¦ç»†æ³¨é‡Šçš„ç»“æœï¼š

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from timm.layers import weight_init

# å®šä¹‰æ¿€æ´»å‡½æ•°ç±»ï¼Œç»§æ‰¿è‡ªReLU
class Activation(nn.ReLU):
    def __init__(self, dim, act_num=3, deploy=False):
        super(Activation, self).__init__()
        self.deploy = deploy  # æ˜¯å¦å¤„äºéƒ¨ç½²æ¨¡å¼
        # æƒé‡å‚æ•°ï¼Œå½¢çŠ¶ä¸º (dim, 1, act_num*2 + 1, act_num*2 + 1)
        self.weight = torch.nn.Parameter(torch.randn(dim, 1, act_num*2 + 1, act_num*2 + 1))
        self.bias = None  # åç½®åˆå§‹åŒ–ä¸ºNone
        self.bn = nn.BatchNorm2d(dim, eps=1e-6)  # æ‰¹å½’ä¸€åŒ–å±‚
        self.dim = dim  # è¾“å…¥ç»´åº¦
        self.act_num = act_num  # æ¿€æ´»å‡½æ•°æ•°é‡
        weight_init.trunc_normal_(self.weight, std=.02)  # æƒé‡åˆå§‹åŒ–

    def forward(self, x):
        # å‰å‘ä¼ æ’­
        if self.deploy:
            # åœ¨éƒ¨ç½²æ¨¡å¼ä¸‹ï¼Œè¿›è¡Œå·ç§¯æ“ä½œ
            return F.conv2d(
                super(Activation, self).forward(x), 
                self.weight, self.bias, padding=(self.act_num*2 + 1)//2, groups=self.dim)
        else:
            # åœ¨è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œå…ˆè¿›è¡Œå·ç§¯ï¼Œå†è¿›è¡Œæ‰¹å½’ä¸€åŒ–
            return self.bn(F.conv2d(
                super(Activation, self).forward(x),
                self.weight, padding=self.act_num, groups=self.dim))

    def switch_to_deploy(self):
        # åˆ‡æ¢åˆ°éƒ¨ç½²æ¨¡å¼
        if not self.deploy:
            kernel, bias = self._fuse_bn_tensor(self.weight, self.bn)  # èåˆæƒé‡å’Œæ‰¹å½’ä¸€åŒ–
            self.weight.data = kernel
            self.bias = torch.nn.Parameter(torch.zeros(self.dim))
            self.bias.data = bias
            self.__delattr__('bn')  # åˆ é™¤bnå±æ€§
            self.deploy = True  # æ›´æ–°çŠ¶æ€ä¸ºéƒ¨ç½²æ¨¡å¼

    def _fuse_bn_tensor(self, weight, bn):
        # èåˆå·ç§¯å±‚æƒé‡å’Œæ‰¹å½’ä¸€åŒ–å±‚çš„å‚æ•°
        kernel = weight
        running_mean = bn.running_mean
        running_var = bn.running_var
        gamma = bn.weight
        beta = bn.bias
        eps = bn.eps
        std = (running_var + eps).sqrt()  # è®¡ç®—æ ‡å‡†å·®
        t = (gamma / std).reshape(-1, 1, 1, 1)  # è®¡ç®—ç¼©æ”¾å› å­
        return kernel * t, beta + (0 - running_mean) * gamma / std  # è¿”å›èåˆåçš„æƒé‡å’Œåç½®

# å®šä¹‰ç½‘ç»œçš„åŸºæœ¬æ¨¡å—
class Block(nn.Module):
    def __init__(self, dim, dim_out, act_num=3, stride=2, deploy=False):
        super().__init__()
        self.deploy = deploy
        # æ ¹æ®æ˜¯å¦éƒ¨ç½²é€‰æ‹©ä¸åŒçš„å·ç§¯ç»“æ„
        if self.deploy:
            self.conv = nn.Conv2d(dim, dim_out, kernel_size=1)
        else:
            self.conv1 = nn.Sequential(
                nn.Conv2d(dim, dim, kernel_size=1),
                nn.BatchNorm2d(dim, eps=1e-6),
            )
            self.conv2 = nn.Sequential(
                nn.Conv2d(dim, dim_out, kernel_size=1),
                nn.BatchNorm2d(dim_out, eps=1e-6)
            )
        # æ± åŒ–å±‚çš„é€‰æ‹©
        self.pool = nn.MaxPool2d(stride) if stride != 1 else nn.Identity()
        self.act = Activation(dim_out, act_num)  # æ¿€æ´»å‡½æ•°

    def forward(self, x):
        # å‰å‘ä¼ æ’­
        if self.deploy:
            x = self.conv(x)  # åœ¨éƒ¨ç½²æ¨¡å¼ä¸‹ç›´æ¥å·ç§¯
        else:
            x = self.conv1(x)  # è®­ç»ƒæ¨¡å¼ä¸‹å…ˆå·ç§¯å†æ‰¹å½’ä¸€åŒ–
            x = F.leaky_relu(x, negative_slope=1)  # ä½¿ç”¨Leaky ReLUæ¿€æ´»
            x = self.conv2(x)  # å†æ¬¡å·ç§¯

        x = self.pool(x)  # æ± åŒ–
        x = self.act(x)  # æ¿€æ´»
        return x

# å®šä¹‰ä¸»ç½‘ç»œç»“æ„
class VanillaNet(nn.Module):
    def __init__(self, in_chans=3, num_classes=1000, dims=[96, 192, 384, 768], 
                 drop_rate=0, act_num=3, strides=[2,2,2,1], deploy=False):
        super().__init__()
        self.deploy = deploy
        # æ„å»ºsteméƒ¨åˆ†
        if self.deploy:
            self.stem = nn.Sequential(
                nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),
                Activation(dims[0], act_num)
            )
        else:
            self.stem1 = nn.Sequential(
                nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),
                nn.BatchNorm2d(dims[0], eps=1e-6),
            )
            self.stem2 = nn.Sequential(
                nn.Conv2d(dims[0], dims[0], kernel_size=1, stride=1),
                nn.BatchNorm2d(dims[0], eps=1e-6),
                Activation(dims[0], act_num)
            )

        self.stages = nn.ModuleList()  # å­˜å‚¨ç½‘ç»œçš„å„ä¸ªé˜¶æ®µ
        for i in range(len(strides)):
            stage = Block(dim=dims[i], dim_out=dims[i+1], act_num=act_num, stride=strides[i], deploy=deploy)
            self.stages.append(stage)  # æ·»åŠ é˜¶æ®µ

    def forward(self, x):
        # å‰å‘ä¼ æ’­
        if self.deploy:
            x = self.stem(x)  # éƒ¨ç½²æ¨¡å¼ä¸‹ç›´æ¥é€šè¿‡stem
        else:
            x = self.stem1(x)  # è®­ç»ƒæ¨¡å¼ä¸‹é€šè¿‡stem1
            x = F.leaky_relu(x, negative_slope=1)  # æ¿€æ´»
            x = self.stem2(x)  # é€šè¿‡stem2

        for stage in self.stages:
            x = stage(x)  # é€šè¿‡æ¯ä¸ªé˜¶æ®µ
        return x

    def switch_to_deploy(self):
        # åˆ‡æ¢åˆ°éƒ¨ç½²æ¨¡å¼
        if not self.deploy:
            # èåˆstem1å’Œstem2çš„å‚æ•°
            kernel, bias = self._fuse_bn_tensor(self.stem1[0], self.stem1[1])
            self.stem1[0].weight.data = kernel
            self.stem1[0].bias.data = bias
            self.stem = nn.Sequential(self.stem1[0], self.stem2[2])  # æ›´æ–°stem
            for stage in self.stages:
                stage.switch_to_deploy()  # æ›´æ–°æ¯ä¸ªé˜¶æ®µ
            self.deploy = True  # æ›´æ–°çŠ¶æ€ä¸ºéƒ¨ç½²æ¨¡å¼

def update_weight(model_dict, weight_dict):
    # æ›´æ–°æ¨¡å‹æƒé‡
    temp_dict = {}
    for k, v in weight_dict.items():
        if k in model_dict.keys() and model_dict[k].shape == v.shape:
            temp_dict[k] = v
    model_dict.update(temp_dict)  # æ›´æ–°æƒé‡
    return model_dict

# å®šä¹‰ä¸åŒç‰ˆæœ¬çš„VanillaNet
def vanillanet_5(pretrained='', **kwargs):
    model = VanillaNet(dims=[128*4, 256*4, 512*4, 1024*4], strides=[2,2,2], **kwargs)
    if pretrained:
        weights = torch.load(pretrained)['model_ema']
        model.load_state_dict(update_weight(model.state_dict(), weights))
    return model

# å…¶ä»–ç‰ˆæœ¬ç±»ä¼¼...

if __name__ == '__main__':
    inputs = torch.randn((1, 3, 640, 640))  # è¾“å…¥æ•°æ®
    model = vanillanet_10()  # åˆ›å»ºæ¨¡å‹
    pred = model(inputs)  # å‰å‘ä¼ æ’­
    for i in pred:
        print(i.size())  # è¾“å‡ºæ¯å±‚çš„å°ºå¯¸
```

### ä»£ç åˆ†æ
1. **Activationç±»**ï¼šè‡ªå®šä¹‰çš„æ¿€æ´»å‡½æ•°ç±»ï¼Œç»§æ‰¿è‡ªReLUï¼Œæ”¯æŒæ‰¹å½’ä¸€åŒ–å’Œæƒé‡èåˆã€‚
2. **Blockç±»**ï¼šæ„å»ºç½‘ç»œçš„åŸºæœ¬æ¨¡å—ï¼ŒåŒ…å«å·ç§¯å±‚ã€æ± åŒ–å±‚å’Œæ¿€æ´»å‡½æ•°ã€‚
3. **VanillaNetç±»**ï¼šä¸»ç½‘ç»œç»“æ„ï¼ŒåŒ…å«å¤šä¸ªBlockï¼Œæ”¯æŒä¸åŒçš„è¾“å…¥é€šé“å’Œè¾“å‡ºç»´åº¦ã€‚
4. **æƒé‡æ›´æ–°å‡½æ•°**ï¼šç”¨äºåŠ è½½é¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡ï¼Œå¹¶æ›´æ–°å½“å‰æ¨¡å‹çš„æƒé‡ã€‚
5. **ä¸åŒç‰ˆæœ¬çš„VanillaNet**ï¼šæä¾›äº†å¤šç§ä¸åŒé…ç½®çš„VanillaNetæ¨¡å‹åˆ›å»ºå‡½æ•°ã€‚

### æ€»ç»“
è¯¥ä»£ç å®ç°äº†ä¸€ä¸ªçµæ´»çš„å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„ï¼Œæ”¯æŒå¤šç§é…ç½®å’Œé¢„è®­ç»ƒæƒé‡åŠ è½½ï¼Œé€‚ç”¨äºå›¾åƒåˆ†ç±»ç­‰ä»»åŠ¡ã€‚

è¿™ä¸ªæ–‡ä»¶æ˜¯ä¸€ä¸ªå®ç°äº†VanillaNetæ¨¡å‹çš„PyTorchä»£ç ï¼Œä¸»è¦ç”¨äºå›¾åƒåˆ†ç±»ç­‰è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚ä»£ç çš„ç»“æ„åŒ…æ‹¬æ¨¡å‹çš„å®šä¹‰ã€å„ä¸ªç»„ä»¶çš„å®ç°ä»¥åŠä¸åŒç‰ˆæœ¬çš„VanillaNetçš„æ„å»ºå‡½æ•°ã€‚

é¦–å…ˆï¼Œæ–‡ä»¶ä¸­å¼•å…¥äº†å¿…è¦çš„åº“ï¼ŒåŒ…æ‹¬PyTorchåŠå…¶ç¥ç»ç½‘ç»œæ¨¡å—ã€ä¸€äº›åŠŸèƒ½æ€§æ¨¡å—ä»¥åŠNumPyã€‚æ¥ç€ï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º`activation`çš„ç±»ï¼Œå®ƒç»§æ‰¿è‡ª`nn.ReLU`ï¼Œç”¨äºå®ç°è‡ªå®šä¹‰çš„æ¿€æ´»å‡½æ•°ã€‚è¿™ä¸ªç±»åœ¨åˆå§‹åŒ–æ—¶ä¼šåˆ›å»ºä¸€ä¸ªæƒé‡å‚æ•°å’Œä¸€ä¸ªæ‰¹å½’ä¸€åŒ–å±‚ï¼Œå¹¶åœ¨å‰å‘ä¼ æ’­ä¸­æ ¹æ®æ˜¯å¦å¤„äºéƒ¨ç½²æ¨¡å¼ï¼ˆ`deploy`ï¼‰æ¥é€‰æ‹©ä¸åŒçš„è®¡ç®—æ–¹å¼ã€‚`switch_to_deploy`æ–¹æ³•ç”¨äºå°†æ¨¡å‹åˆ‡æ¢åˆ°éƒ¨ç½²æ¨¡å¼ï¼Œèåˆæ‰¹å½’ä¸€åŒ–çš„æƒé‡ã€‚

æ¥ä¸‹æ¥æ˜¯`Block`ç±»çš„å®šä¹‰ï¼Œå®ƒæ˜¯VanillaNetçš„åŸºæœ¬æ„å»ºå—ã€‚æ¯ä¸ªBlockåŒ…å«ä¸¤ä¸ªå·ç§¯å±‚å’Œä¸€ä¸ªæ¿€æ´»å±‚ï¼Œå¯èƒ½è¿˜ä¼šæœ‰æ± åŒ–å±‚ã€‚æ ¹æ®`deploy`å‚æ•°çš„ä¸åŒï¼ŒBlockä¼šé€‰æ‹©ä¸åŒçš„å‰å‘ä¼ æ’­æ–¹å¼ã€‚`switch_to_deploy`æ–¹æ³•åŒæ ·ç”¨äºå°†Blockåˆ‡æ¢åˆ°éƒ¨ç½²æ¨¡å¼ã€‚

`VanillaNet`ç±»æ˜¯æ•´ä¸ªæ¨¡å‹çš„æ ¸å¿ƒï¼ŒåŒ…å«äº†å¤šä¸ªBlockå’Œä¸€ä¸ªåˆå§‹å·ç§¯å±‚ï¼ˆstemï¼‰ã€‚åœ¨åˆå§‹åŒ–æ—¶ï¼Œæ¨¡å‹ä¼šæ ¹æ®è¾“å…¥é€šé“æ•°ã€ç±»åˆ«æ•°ã€å„å±‚çš„ç»´åº¦ã€æ­¥å¹…ç­‰å‚æ•°æ¥æ„å»ºç½‘ç»œç»“æ„ã€‚`forward`æ–¹æ³•å®šä¹‰äº†æ•°æ®çš„å‰å‘ä¼ æ’­è¿‡ç¨‹ï¼Œè¿”å›ä¸åŒå°ºåº¦çš„ç‰¹å¾å›¾ã€‚

æ­¤å¤–ï¼Œæ–‡ä»¶ä¸­è¿˜å®šä¹‰äº†ä¸€äº›è¾…åŠ©å‡½æ•°ï¼Œæ¯”å¦‚`update_weight`ç”¨äºæ›´æ–°æ¨¡å‹çš„æƒé‡ï¼Œ`vanillanet_x`ç³»åˆ—å‡½æ•°ç”¨äºåˆ›å»ºä¸åŒç‰ˆæœ¬çš„VanillaNetæ¨¡å‹ï¼Œå¹¶æ”¯æŒåŠ è½½é¢„è®­ç»ƒæƒé‡ã€‚

æœ€åï¼Œåœ¨`__main__`éƒ¨åˆ†ï¼Œä»£ç åˆ›å»ºäº†ä¸€ä¸ªè¾“å…¥å¼ é‡å¹¶å®ä¾‹åŒ–äº†ä¸€ä¸ªVanillaNetæ¨¡å‹ï¼Œç„¶åé€šè¿‡æ¨¡å‹è¿›è¡Œå‰å‘ä¼ æ’­å¹¶æ‰“å°è¾“å‡ºç‰¹å¾å›¾çš„å°ºå¯¸ã€‚

æ•´ä½“æ¥çœ‹ï¼Œè¿™ä¸ªæ–‡ä»¶å®ç°äº†ä¸€ä¸ªçµæ´»ä¸”å¯æ‰©å±•çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œé€‚ç”¨äºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œå¹¶ä¸”æä¾›äº†æ–¹ä¾¿çš„é¢„è®­ç»ƒæƒé‡åŠ è½½åŠŸèƒ½ã€‚

#### 10.2 test_selective_scan_speed.py

ä»¥ä¸‹æ˜¯ç»è¿‡ç®€åŒ–å’Œæ³¨é‡Šçš„æ ¸å¿ƒä»£ç éƒ¨åˆ†ï¼Œä¸»è¦é›†ä¸­åœ¨ `build_selective_scan_fn` å‡½æ•°åŠå…¶å†…éƒ¨çš„ `SelectiveScanFn` ç±»ä¸Šã€‚è¯¥ä»£ç å®ç°äº†ä¸€ä¸ªé€‰æ‹©æ€§æ‰«æï¼ˆSelective Scanï¼‰æ“ä½œçš„å‰å‘å’Œåå‘ä¼ æ’­åŠŸèƒ½ã€‚

```python
import torch
import torch.nn.functional as F

def build_selective_scan_fn(selective_scan_cuda: object = None, mode="mamba_ssm", tag=None):
    """
    æ„å»ºé€‰æ‹©æ€§æ‰«æå‡½æ•°ã€‚
    
    å‚æ•°:
    selective_scan_cuda: ç”¨äºCUDAå®ç°çš„é€‰æ‹©æ€§æ‰«æå‡½æ•°ã€‚
    mode: æ¨¡å¼é€‰æ‹©ï¼Œç”¨äºä¸åŒçš„é€‰æ‹©æ€§æ‰«æå®ç°ã€‚
    tag: æ ‡ç­¾ï¼Œç”¨äºæ ‡è¯†å‡½æ•°ã€‚
    
    è¿”å›:
    selective_scan_fn: é€‰æ‹©æ€§æ‰«æå‡½æ•°ã€‚
    """
    
    class SelectiveScanFn(torch.autograd.Function):
        @staticmethod
        def forward(ctx, u, delta, A, B, C, D=None, z=None, delta_bias=None, delta_softplus=False, return_last_state=False, nrows=1, backnrows=-1):
            """
            å‰å‘ä¼ æ’­å‡½æ•°ã€‚
            
            å‚æ•°:
            ctx: ä¸Šä¸‹æ–‡å¯¹è±¡ï¼Œç”¨äºä¿å­˜çŠ¶æ€ã€‚
            u, delta, A, B, C, D, z: è¾“å…¥å¼ é‡ã€‚
            delta_bias: åç½®é¡¹ã€‚
            delta_softplus: æ˜¯å¦ä½¿ç”¨softplusã€‚
            return_last_state: æ˜¯å¦è¿”å›æœ€åçŠ¶æ€ã€‚
            nrows, backnrows: è¡Œæ•°å‚æ•°ã€‚
            
            è¿”å›:
            out: è¾“å‡ºå¼ é‡ã€‚
            last_state: æœ€åçŠ¶æ€ï¼ˆå¯é€‰ï¼‰ã€‚
            """
            # ç¡®ä¿è¾“å…¥å¼ é‡æ˜¯è¿ç»­çš„
            u = u.contiguous() if u.stride(-1) != 1 else u
            delta = delta.contiguous() if delta.stride(-1) != 1 else delta
            if D is not None:
                D = D.contiguous()
            B = B.contiguous() if B.stride(-1) != 1 else B
            C = C.contiguous() if C.stride(-1) != 1 else C
            if z is not None and z.stride(-1) != 1:
                z = z.contiguous()

            # å¤„ç†è¾“å…¥å¼ é‡çš„ç»´åº¦
            if B.dim() == 3:
                B = rearrange(B, "b dstate l -> b 1 dstate l")
                ctx.squeeze_B = True
            if C.dim() == 3:
                C = rearrange(C, "b dstate l -> b 1 dstate l")
                ctx.squeeze_C = True

            # æ£€æŸ¥è¾“å…¥çš„å½¢çŠ¶å’Œç»´åº¦
            assert u.shape[1] % (B.shape[1] * nrows) == 0 
            assert nrows in [1, 2, 3, 4]

            if backnrows > 0:
                assert u.shape[1] % (B.shape[1] * backnrows) == 0 
                assert backnrows in [1, 2, 3, 4]
            else:
                backnrows = nrows
            ctx.backnrows = backnrows
            
            # è°ƒç”¨CUDAå®ç°çš„å‰å‘å‡½æ•°
            if mode == "mamba_ssm":
                out, x, *rest = selective_scan_cuda.fwd(u, delta, A, B, C, D, z, delta_bias, delta_softplus)
            else:
                raise NotImplementedError

            ctx.delta_softplus = delta_softplus
            ctx.has_z = z is not None

            last_state = x[:, :, -1, 1::2]  # è·å–æœ€åçŠ¶æ€
            ctx.save_for_backward(u, delta, A, B, C, D, delta_bias, x)
            return out if not return_last_state else (out, last_state)

        @staticmethod
        def backward(ctx, dout):
            """
            åå‘ä¼ æ’­å‡½æ•°ã€‚
            
            å‚æ•°:
            ctx: ä¸Šä¸‹æ–‡å¯¹è±¡ï¼ŒåŒ…å«å‰å‘ä¼ æ’­ä¸­ä¿å­˜çš„çŠ¶æ€ã€‚
            dout: ä¸Šæ¸¸æ¢¯åº¦ã€‚
            
            è¿”å›:
            du, ddelta, dA, dB, dC, dD, dz, ddelta_bias: å„ä¸ªè¾“å…¥çš„æ¢¯åº¦ã€‚
            """
            u, delta, A, B, C, D, delta_bias, x = ctx.saved_tensors
            dout = dout.contiguous() if dout.stride(-1) != 1 else dout
            
            # è°ƒç”¨CUDAå®ç°çš„åå‘å‡½æ•°
            du, ddelta, dA, dB, dC, dD, ddelta_bias, *rest = selective_scan_cuda.bwd(
                u, delta, A, B, C, D, delta_bias, dout, x, ctx.delta_softplus, ctx.backnrows
            )

            # è¿”å›å„ä¸ªè¾“å…¥çš„æ¢¯åº¦
            return (du, ddelta, dA, dB, dC, dD if D is not None else None, None, ddelta_bias if delta_bias is not None else None)

    def selective_scan_fn(u, delta, A, B, C, D=None, z=None, delta_bias=None, delta_softplus=False, return_last_state=False, nrows=1, backnrows=-1):
        """
        é€‰æ‹©æ€§æ‰«æå‡½æ•°çš„å°è£…ã€‚
        """
        return SelectiveScanFn.apply(u, delta, A, B, C, D, z, delta_bias, delta_softplus, return_last_state, nrows, backnrows)

    return selective_scan_fn
```

### ä»£ç æ³¨é‡Šè¯´æ˜ï¼š
1. **build_selective_scan_fn**: è¯¥å‡½æ•°ç”¨äºæ„å»ºé€‰æ‹©æ€§æ‰«æçš„å‰å‘å’Œåå‘ä¼ æ’­å‡½æ•°ï¼Œæ¥å—CUDAå®ç°å’Œæ¨¡å¼ä½œä¸ºå‚æ•°ã€‚
2. **SelectiveScanFn**: è¿™æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰çš„PyTorchå‡½æ•°ï¼ŒåŒ…å«å‰å‘å’Œåå‘ä¼ æ’­çš„å®ç°ã€‚
   - **forward**: å¤„ç†è¾“å…¥å¼ é‡ï¼Œæ£€æŸ¥å½¢çŠ¶å’Œç»´åº¦ï¼Œè°ƒç”¨CUDAå®ç°çš„å‰å‘å‡½æ•°ï¼Œå¹¶è¿”å›è¾“å‡ºå’Œæœ€åçŠ¶æ€ï¼ˆå¦‚æœéœ€è¦ï¼‰ã€‚
   - **backward**: è®¡ç®—æ¢¯åº¦ï¼Œè°ƒç”¨CUDAå®ç°çš„åå‘å‡½æ•°ï¼Œå¹¶è¿”å›å„ä¸ªè¾“å…¥çš„æ¢¯åº¦ã€‚
3. **selective_scan_fn**: å°è£…äº†`SelectiveScanFn`çš„è°ƒç”¨ï¼Œç®€åŒ–äº†ç”¨æˆ·çš„æ¥å£ã€‚

è¿™ä¸ªç®€åŒ–çš„ä»£ç éƒ¨åˆ†ä¿ç•™äº†æ ¸å¿ƒåŠŸèƒ½ï¼ŒåŒæ—¶æä¾›äº†è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼Œå¸®åŠ©ç†è§£æ¯ä¸ªéƒ¨åˆ†çš„ä½œç”¨ã€‚

è¿™ä¸ªç¨‹åºæ–‡ä»¶ `test_selective_scan_speed.py` ä¸»è¦ç”¨äºæµ‹è¯•å’Œæ¯”è¾ƒä¸åŒé€‰æ‹©æ€§æ‰«æï¼ˆselective scanï¼‰ç®—æ³•çš„é€Ÿåº¦ã€‚æ–‡ä»¶ä¸­åŒ…å«äº†å¤šä¸ªå‡½æ•°å’Œç±»ï¼Œä¸»è¦æ˜¯ç”¨ PyTorch å®ç°çš„è‡ªå®šä¹‰å‰å‘å’Œåå‘ä¼ æ’­æ“ä½œã€‚ä»¥ä¸‹æ˜¯å¯¹æ–‡ä»¶ä¸­ä»£ç çš„é€æ­¥è®²è§£ã€‚

é¦–å…ˆï¼Œæ–‡ä»¶å¯¼å…¥äº†ä¸€äº›å¿…è¦çš„åº“ï¼ŒåŒ…æ‹¬ `torch` å’Œ `pytest`ï¼Œä»¥åŠä¸€äº›ç”¨äºå¤„ç†å¼ é‡çš„å·¥å…·ï¼Œå¦‚ `einops` å’Œ `functools`ã€‚è¿™äº›åº“ä¸ºåç»­çš„è®¡ç®—æä¾›äº†åŸºç¡€ã€‚

æ¥ä¸‹æ¥ï¼Œå®šä¹‰äº†ä¸€ä¸ª `build_selective_scan_fn` å‡½æ•°ï¼Œè¯¥å‡½æ•°ç”¨äºæ„å»ºé€‰æ‹©æ€§æ‰«æçš„è‡ªå®šä¹‰å‡½æ•°ã€‚å®ƒå†…éƒ¨å®šä¹‰äº†ä¸€ä¸ª `SelectiveScanFn` ç±»ï¼Œç»§æ‰¿è‡ª `torch.autograd.Function`ï¼Œè¿™ä¸ªç±»å®ç°äº†å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­çš„é€»è¾‘ã€‚

åœ¨ `SelectiveScanFn` ç±»ä¸­ï¼Œ`forward` æ–¹æ³•è´Ÿè´£å¤„ç†è¾“å…¥æ•°æ®å¹¶æ‰§è¡Œé€‰æ‹©æ€§æ‰«æçš„å‰å‘è®¡ç®—ã€‚å®ƒé¦–å…ˆç¡®ä¿è¾“å…¥å¼ é‡æ˜¯è¿ç»­çš„ï¼Œå¹¶æ ¹æ®è¾“å…¥çš„ç»´åº¦è°ƒæ•´å¼ é‡çš„å½¢çŠ¶ã€‚ç„¶åï¼Œæ ¹æ®ä¸åŒçš„æ¨¡å¼ï¼ˆå¦‚ "mamba_ssm"ã€"sscore" ç­‰ï¼‰ï¼Œè°ƒç”¨ç›¸åº”çš„ CUDA åç«¯å‡½æ•°è¿›è¡Œè®¡ç®—ã€‚è®¡ç®—ç»“æœåŒ…æ‹¬è¾“å‡ºå¼ é‡å’Œä¸­é—´çŠ¶æ€ï¼Œæœ€åå°†å¿…è¦çš„å¼ é‡ä¿å­˜åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼Œä»¥ä¾¿åœ¨åå‘ä¼ æ’­æ—¶ä½¿ç”¨ã€‚

`backward` æ–¹æ³•å®ç°äº†åå‘ä¼ æ’­çš„é€»è¾‘ï¼Œè®¡ç®—æ¢¯åº¦å¹¶è¿”å›ã€‚å®ƒæ ¹æ®å‰å‘ä¼ æ’­æ—¶çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè°ƒç”¨ç›¸åº”çš„ CUDA åç«¯å‡½æ•°æ¥è®¡ç®—æ¢¯åº¦ã€‚

æ¥ç€ï¼Œå®šä¹‰äº† `selective_scan_ref` å‡½æ•°ï¼Œè¿™æ˜¯ä¸€ä¸ªå‚è€ƒå®ç°ï¼Œç”¨äºæ‰§è¡Œé€‰æ‹©æ€§æ‰«æçš„è®¡ç®—ã€‚å®ƒçš„å®ç°é€»è¾‘ä¸ `SelectiveScanFn` ç±»ä¼¼ï¼Œä½†ä½¿ç”¨çš„æ˜¯çº¯ Python å’Œ PyTorch çš„å¼ é‡æ“ä½œï¼Œé€‚åˆç”¨äºéªŒè¯å’Œæ¯”è¾ƒæ€§èƒ½ã€‚

éšåï¼Œå®šä¹‰äº† `selective_scan_easy` å’Œ `selective_scan_easy_v2` å‡½æ•°ï¼Œè¿™ä¸¤ä¸ªå‡½æ•°å®ç°äº†é€‰æ‹©æ€§æ‰«æçš„ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸»è¦ç”¨äºå¤„ç†è¾“å…¥æ•°æ®å¹¶è¿”å›è®¡ç®—ç»“æœã€‚

æ–‡ä»¶çš„æœ€åéƒ¨åˆ†æ˜¯ `test_speed` å‡½æ•°ï¼Œå®ƒç”¨äºæµ‹è¯•ä¸åŒé€‰æ‹©æ€§æ‰«æå®ç°çš„é€Ÿåº¦ã€‚å‡½æ•°é¦–å…ˆè®¾ç½®äº†ä¸€äº›å‚æ•°ï¼ŒåŒ…æ‹¬æ•°æ®ç±»å‹ã€åºåˆ—é•¿åº¦ã€æ‰¹é‡å¤§å°ç­‰ã€‚ç„¶åç”Ÿæˆéšæœºè¾“å…¥æ•°æ®ï¼Œå¹¶ä½¿ç”¨ä¸åŒçš„é€‰æ‹©æ€§æ‰«æå®ç°è¿›è¡Œå‰å‘å’Œåå‘è®¡ç®—ï¼Œè®°å½•æ¯ç§å®ç°çš„æ‰§è¡Œæ—¶é—´ã€‚

åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨ `torch.no_grad()` æ¥é¿å…è®¡ç®—æ¢¯åº¦ï¼Œä»¥ä¾¿åªæµ‹é‡å‰å‘ä¼ æ’­çš„æ—¶é—´ã€‚ä½¿ç”¨ `torch.cuda.synchronize()` ç¡®ä¿æ‰€æœ‰ CUDA æ“ä½œå®Œæˆåå†è®°å½•æ—¶é—´ã€‚

æœ€åï¼Œæµ‹è¯•ç»“æœä¼šæ‰“å°åˆ°æ§åˆ¶å°ï¼Œæ˜¾ç¤ºæ¯ç§å®ç°çš„å‰å‘å’Œå‰å‘åå‘ä¼ æ’­çš„è€—æ—¶ã€‚

æ•´ä½“è€Œè¨€ï¼Œè¿™ä¸ªç¨‹åºæ–‡ä»¶çš„ç›®çš„æ˜¯é€šè¿‡ä¸åŒçš„å®ç°æ¥æ¯”è¾ƒé€‰æ‹©æ€§æ‰«æç®—æ³•çš„æ€§èƒ½ï¼Œå¸®åŠ©å¼€å‘è€…é€‰æ‹©æœ€ä¼˜çš„å®ç°æ–¹æ¡ˆã€‚

#### 10.3 fadc.py

ä»¥ä¸‹æ˜¯ä»£ç ä¸­æœ€æ ¸å¿ƒçš„éƒ¨åˆ†ï¼Œå¹¶é™„ä¸Šè¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼š

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class OmniAttention(nn.Module):
    def __init__(self, in_planes, out_planes, kernel_size, groups=1, reduction=0.0625, kernel_num=4, min_channel=16):
        super(OmniAttention, self).__init__()
        # è®¡ç®—æ³¨æ„åŠ›é€šé“æ•°
        attention_channel = max(int(in_planes * reduction), min_channel)
        self.kernel_size = kernel_size
        self.kernel_num = kernel_num
        self.temperature = 1.0  # æ¸©åº¦å‚æ•°ï¼Œç”¨äºè°ƒæ•´æ³¨æ„åŠ›åˆ†å¸ƒ

        # å®šä¹‰å„ä¸ªå±‚
        self.avgpool = nn.AdaptiveAvgPool2d(1)  # è‡ªé€‚åº”å¹³å‡æ± åŒ–
        self.fc = nn.Conv2d(in_planes, attention_channel, 1, bias=False)  # å…¨è¿æ¥å±‚
        self.bn = nn.BatchNorm2d(attention_channel)  # æ‰¹å½’ä¸€åŒ–
        self.relu = nn.ReLU(inplace=True)  # ReLUæ¿€æ´»å‡½æ•°

        # å®šä¹‰é€šé“æ³¨æ„åŠ›
        self.channel_fc = nn.Conv2d(attention_channel, in_planes, 1, bias=True)
        self.func_channel = self.get_channel_attention

        # å®šä¹‰æ»¤æ³¢å™¨æ³¨æ„åŠ›
        if in_planes == groups and in_planes == out_planes:  # æ·±åº¦å·ç§¯
            self.func_filter = self.skip
        else:
            self.filter_fc = nn.Conv2d(attention_channel, out_planes, 1, bias=True)
            self.func_filter = self.get_filter_attention

        # å®šä¹‰ç©ºé—´æ³¨æ„åŠ›
        if kernel_size == 1:  # ç‚¹å·ç§¯
            self.func_spatial = self.skip
        else:
            self.spatial_fc = nn.Conv2d(attention_channel, kernel_size * kernel_size, 1, bias=True)
            self.func_spatial = self.get_spatial_attention

        # å®šä¹‰æ ¸æ³¨æ„åŠ›
        if kernel_num == 1:
            self.func_kernel = self.skip
        else:
            self.kernel_fc = nn.Conv2d(attention_channel, kernel_num, 1, bias=True)
            self.func_kernel = self.get_kernel_attention

        self._initialize_weights()  # åˆå§‹åŒ–æƒé‡

    def _initialize_weights(self):
        # åˆå§‹åŒ–å·ç§¯å±‚å’Œæ‰¹å½’ä¸€åŒ–å±‚çš„æƒé‡
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            if isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    @staticmethod
    def skip(_):
        return 1.0  # è·³è¿‡æ“ä½œï¼Œè¿”å›1.0

    def get_channel_attention(self, x):
        # è®¡ç®—é€šé“æ³¨æ„åŠ›
        channel_attention = torch.sigmoid(self.channel_fc(x).view(x.size(0), -1, 1, 1) / self.temperature)
        return channel_attention

    def get_filter_attention(self, x):
        # è®¡ç®—æ»¤æ³¢å™¨æ³¨æ„åŠ›
        filter_attention = torch.sigmoid(self.filter_fc(x).view(x.size(0), -1, 1, 1) / self.temperature)
        return filter_attention

    def get_spatial_attention(self, x):
        # è®¡ç®—ç©ºé—´æ³¨æ„åŠ›
        spatial_attention = self.spatial_fc(x).view(x.size(0), 1, 1, 1, self.kernel_size, self.kernel_size)
        spatial_attention = torch.sigmoid(spatial_attention / self.temperature)
        return spatial_attention

    def get_kernel_attention(self, x):
        # è®¡ç®—æ ¸æ³¨æ„åŠ›
        kernel_attention = self.kernel_fc(x).view(x.size(0), -1, 1, 1, 1, 1)
        kernel_attention = F.softmax(kernel_attention / self.temperature, dim=1)
        return kernel_attention

    def forward(self, x):
        # å‰å‘ä¼ æ’­
        x = self.avgpool(x)  # è‡ªé€‚åº”å¹³å‡æ± åŒ–
        x = self.fc(x)  # å…¨è¿æ¥å±‚
        x = self.bn(x)  # æ‰¹å½’ä¸€åŒ–
        x = self.relu(x)  # ReLUæ¿€æ´»
        return self.func_channel(x), self.func_filter(x), self.func_spatial(x), self.func_kernel(x)  # è¿”å›å„ä¸ªæ³¨æ„åŠ›

# ç”Ÿæˆæ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”çš„å‡½æ•°
def generate_laplacian_pyramid(input_tensor, num_levels, size_align=True, mode='bilinear'):
    pyramid = []  # å­˜å‚¨é‡‘å­—å¡”å±‚
    current_tensor = input_tensor  # å½“å‰å¼ é‡
    _, _, H, W = current_tensor.shape  # è·å–è¾“å…¥å¼ é‡çš„å½¢çŠ¶
    for _ in range(num_levels):
        b, _, h, w = current_tensor.shape  # è·å–å½“å‰å¼ é‡çš„å½¢çŠ¶
        # ä¸‹é‡‡æ ·
        downsampled_tensor = F.interpolate(current_tensor, (h//2 + h%2, w//2 + w%2), mode=mode, align_corners=(H%2) == 1)
        if size_align: 
            # å¯¹é½å¤§å°
            upsampled_tensor = F.interpolate(downsampled_tensor, (H, W), mode=mode, align_corners=(H%2) == 1)
            laplacian = F.interpolate(current_tensor, (H, W), mode=mode, align_corners=(H%2) == 1) - upsampled_tensor
        else:
            upsampled_tensor = F.interpolate(downsampled_tensor, (h, w), mode=mode, align_corners=(H%2) == 1)
            laplacian = current_tensor - upsampled_tensor
        pyramid.append(laplacian)  # æ·»åŠ æ‹‰æ™®æ‹‰æ–¯å±‚
        current_tensor = downsampled_tensor  # æ›´æ–°å½“å‰å¼ é‡
    if size_align: 
        current_tensor = F.interpolate(current_tensor, (H, W), mode=mode, align_corners=(H%2) == 1)
    pyramid.append(current_tensor)  # æ·»åŠ æœ€åä¸€å±‚
    return pyramid  # è¿”å›é‡‘å­—å¡”

class AdaptiveDilatedConv(nn.Module):
    """è‡ªé€‚åº”è†¨èƒ€å·ç§¯çš„å°è£…ç±»"""
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):
        super(AdaptiveDilatedConv, self).__init__()
        # å®šä¹‰å·ç§¯å±‚
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)
        self.omni_attention = OmniAttention(in_channels, out_channels, kernel_size)  # å®ä¾‹åŒ–OmniAttention

    def forward(self, x):
        # å‰å‘ä¼ æ’­
        attention_weights = self.omni_attention(x)  # è®¡ç®—æ³¨æ„åŠ›æƒé‡
        x = self.conv(x)  # å·ç§¯æ“ä½œ
        return x * attention_weights  # è¿”å›åŠ æƒåçš„è¾“å‡º
```

### ä»£ç æ ¸å¿ƒéƒ¨åˆ†è¯´æ˜ï¼š
1. **OmniAttention ç±»**ï¼šå®ç°äº†å¤šç§æ³¨æ„åŠ›æœºåˆ¶ï¼ŒåŒ…æ‹¬é€šé“æ³¨æ„åŠ›ã€æ»¤æ³¢å™¨æ³¨æ„åŠ›ã€ç©ºé—´æ³¨æ„åŠ›å’Œæ ¸æ³¨æ„åŠ›ã€‚é€šè¿‡è¿™äº›æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¯ä»¥åŠ¨æ€è°ƒæ•´ç‰¹å¾å›¾çš„ä¸åŒéƒ¨åˆ†çš„æƒé‡ï¼Œä»è€Œæé«˜æ¨¡å‹çš„è¡¨ç°ã€‚

2. **generate_laplacian_pyramid å‡½æ•°**ï¼šç”¨äºç”Ÿæˆæ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”ï¼Œä¸»è¦ç”¨äºå›¾åƒå¤„ç†ä¸­çš„å¤šå°ºåº¦ç‰¹å¾æå–ã€‚é€šè¿‡é€å±‚ä¸‹é‡‡æ ·å’Œä¸Šé‡‡æ ·ï¼Œå¯ä»¥æå–ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚

3. **AdaptiveDilatedConv ç±»**ï¼šå®ç°äº†è‡ªé€‚åº”è†¨èƒ€å·ç§¯ï¼Œç»“åˆäº†å·ç§¯æ“ä½œå’Œæ³¨æ„åŠ›æœºåˆ¶ã€‚é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ï¼Œèƒ½å¤ŸåŠ¨æ€è°ƒæ•´å·ç§¯æ“ä½œçš„æƒé‡ï¼Œä»è€Œå¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚

è¿™äº›æ ¸å¿ƒéƒ¨åˆ†å…±åŒæ„æˆäº†ä¸€ä¸ªå¼ºå¤§çš„å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„ï¼Œèƒ½å¤Ÿåœ¨å›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­å–å¾—è‰¯å¥½çš„æ•ˆæœã€‚

è¿™ä¸ªç¨‹åºæ–‡ä»¶ `fadc.py` æ˜¯ä¸€ä¸ªåŸºäº PyTorch çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å®ç°ï¼Œä¸»è¦æ¶‰åŠè‡ªé€‚åº”è†¨èƒ€å·ç§¯å’Œé¢‘ç‡é€‰æ‹©æœºåˆ¶ã€‚æ–‡ä»¶ä¸­åŒ…å«å¤šä¸ªç±»å’Œå‡½æ•°ï¼Œä»¥ä¸‹æ˜¯å¯¹ä¸»è¦éƒ¨åˆ†çš„è®²è§£ã€‚

é¦–å…ˆï¼Œæ–‡ä»¶å¯¼å…¥äº†å¿…è¦çš„åº“ï¼ŒåŒ…æ‹¬ PyTorch çš„æ ¸å¿ƒåº“å’Œä¸€äº›å¸¸ç”¨çš„æ¨¡å—ã€‚ç„¶åï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º `OmniAttention` çš„ç±»ï¼Œå®ƒæ˜¯ä¸€ä¸ªè‡ªå®šä¹‰çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚è¿™ä¸ªç±»çš„æ„é€ å‡½æ•°æ¥æ”¶å¤šä¸ªå‚æ•°ï¼ŒåŒ…æ‹¬è¾“å…¥å’Œè¾“å‡ºé€šé“æ•°ã€å·ç§¯æ ¸å¤§å°ã€ç»„æ•°ã€ç¼©å‡æ¯”ä¾‹ç­‰ã€‚å®ƒé€šè¿‡å¤šä¸ªå·ç§¯å±‚å’Œæ¿€æ´»å‡½æ•°æ¥è®¡ç®—é€šé“æ³¨æ„åŠ›ã€è¿‡æ»¤å™¨æ³¨æ„åŠ›ã€ç©ºé—´æ³¨æ„åŠ›å’Œå·ç§¯æ ¸æ³¨æ„åŠ›ã€‚`forward` æ–¹æ³•å°†è¾“å…¥å¼ é‡é€šè¿‡ä¸€ç³»åˆ—æ“ä½œç”Ÿæˆæ³¨æ„åŠ›æƒé‡ï¼Œè¿™äº›æƒé‡å¯ä»¥åœ¨åç»­çš„å·ç§¯æ“ä½œä¸­ä½¿ç”¨ã€‚

æ¥ä¸‹æ¥ï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º `generate_laplacian_pyramid` çš„å‡½æ•°ï¼Œç”¨äºç”Ÿæˆæ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”ã€‚è¯¥å‡½æ•°é€šè¿‡é€å±‚ä¸‹é‡‡æ ·è¾“å…¥å¼ é‡ï¼Œå¹¶è®¡ç®—å½“å‰å±‚ä¸ä¸‹é‡‡æ ·åçš„å¼ é‡ä¹‹é—´çš„å·®å¼‚ï¼Œæ„å»ºé‡‘å­—å¡”ç»“æ„ã€‚æ­¤å‡½æ•°çš„è¾“å‡ºæ˜¯ä¸€ä¸ªåŒ…å«å¤šä¸ªå±‚æ¬¡çš„é‡‘å­—å¡”åˆ—è¡¨ï¼Œé€šå¸¸ç”¨äºå›¾åƒå¤„ç†å’Œç‰¹å¾æå–ã€‚

ç„¶åï¼Œå®šä¹‰äº† `FrequencySelection` ç±»ï¼Œå®ƒç”¨äºé€‰æ‹©ç‰¹å®šé¢‘ç‡çš„ç‰¹å¾ã€‚è¯¥ç±»æ”¯æŒå¤šç§æ“ä½œæ¨¡å¼ï¼ŒåŒ…æ‹¬å¹³å‡æ± åŒ–å’Œæ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”ã€‚æ„é€ å‡½æ•°ä¸­æ ¹æ®è¾“å…¥å‚æ•°åˆå§‹åŒ–å¤šä¸ªå·ç§¯å±‚å’Œé¢‘ç‡é€‰æ‹©æœºåˆ¶ã€‚`forward` æ–¹æ³•æ ¹æ®é€‰æ‹©çš„é¢‘ç‡å¯¹è¾“å…¥ç‰¹å¾è¿›è¡Œå¤„ç†ï¼Œå¹¶è¿”å›åŠ æƒåçš„ç‰¹å¾ã€‚

æ¥ä¸‹æ¥æ˜¯ `AdaptiveDilatedConv` ç±»ï¼Œå®ƒæ˜¯ä¸€ä¸ªè‡ªé€‚åº”è†¨èƒ€å·ç§¯çš„å®ç°ï¼Œç»§æ‰¿è‡ª `ModulatedDeformConv2d`ã€‚è¯¥ç±»çš„æ„é€ å‡½æ•°ä¸­å®šä¹‰äº†å¤šä¸ªå‚æ•°ï¼ŒåŒ…æ‹¬å·ç§¯ç±»å‹ã€åç§»é¢‘ç‡ã€å·ç§¯æ ¸åˆ†è§£ç­‰ã€‚å®ƒçš„ `forward` æ–¹æ³•å®ç°äº†è‡ªé€‚åº”å·ç§¯æ“ä½œï¼Œç»“åˆäº†æ³¨æ„åŠ›æœºåˆ¶å’Œé¢‘ç‡é€‰æ‹©ã€‚

æœ€åï¼Œå®šä¹‰äº† `AdaptiveDilatedDWConv` ç±»ï¼Œå®ƒæ˜¯ä¸€ä¸ªé€‚åº”æ€§è†¨èƒ€æ·±åº¦å·ç§¯çš„å®ç°ã€‚ä¸å‰ä¸€ä¸ªç±»ç±»ä¼¼ï¼Œå®ƒä¹ŸåŒ…å«å¤šä¸ªå·ç§¯å±‚å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œå¹¶åœ¨ `forward` æ–¹æ³•ä¸­å®ç°äº†æ·±åº¦å·ç§¯çš„æ“ä½œã€‚

æ•´ä½“æ¥çœ‹ï¼Œè¿™ä¸ªæ–‡ä»¶å®ç°äº†ä¸€ä¸ªå¤æ‚çš„å·ç§¯ç¥ç»ç½‘ç»œç»“æ„ï¼Œç»“åˆäº†è‡ªé€‚åº”å·ç§¯ã€æ³¨æ„åŠ›æœºåˆ¶å’Œé¢‘ç‡é€‰æ‹©ï¼Œé€‚ç”¨äºå›¾åƒå¤„ç†å’Œç‰¹å¾æå–ç­‰ä»»åŠ¡ã€‚ä»£ç ä¸­ä½¿ç”¨äº†å¤§é‡çš„ PyTorch APIï¼Œå±•ç¤ºäº†æ·±åº¦å­¦ä¹ æ¨¡å‹çš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ã€‚

#### 10.4 dyhead_prune.py

ä»¥ä¸‹æ˜¯ä¿ç•™çš„æ ¸å¿ƒä»£ç éƒ¨åˆ†ï¼Œå¹¶é™„ä¸Šè¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šï¼š

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class DyReLU(nn.Module):
    """åŠ¨æ€ReLUæ¿€æ´»å‡½æ•°æ¨¡å—ï¼Œå…·æœ‰è‡ªé€‚åº”çš„æ¿€æ´»å¼ºåº¦å’Œåç½®ã€‚"""
    def __init__(self, inp, reduction=4, lambda_a=1.0, use_bias=True):
        super(DyReLU, self).__init__()
        self.oup = inp  # è¾“å‡ºé€šé“æ•°
        self.lambda_a = lambda_a * 2  # æ¿€æ´»å¼ºåº¦çš„ç¼©æ”¾å› å­
        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # è‡ªé€‚åº”å¹³å‡æ± åŒ–å±‚

        # æ ¹æ®è¾“å…¥é€šé“æ•°å’Œç¼©å‡æ¯”ä¾‹è®¡ç®—squeezeé€šé“æ•°
        squeeze = inp // reduction
        self.fc = nn.Sequential(
            nn.Linear(inp, squeeze),  # å…¨è¿æ¥å±‚ï¼Œè¾“å…¥ä¸ºinpï¼Œè¾“å‡ºä¸ºsqueeze
            nn.ReLU(inplace=True),  # ReLUæ¿€æ´»å‡½æ•°
            nn.Linear(squeeze, self.oup * 2),  # è¾“å‡ºä¸ºä¸¤å€çš„è¾“å‡ºé€šé“æ•°
            h_sigmoid()  # ä½¿ç”¨h_sigmoidæ¿€æ´»å‡½æ•°
        )

    def forward(self, x):
        """å‰å‘ä¼ æ’­å‡½æ•°ï¼Œè®¡ç®—åŠ¨æ€æ¿€æ´»å€¼ã€‚"""
        b, c, h, w = x.size()  # è·å–è¾“å…¥çš„æ‰¹é‡å¤§å°ã€é€šé“æ•°ã€é«˜åº¦å’Œå®½åº¦
        y = self.avg_pool(x).view(b, c)  # å¯¹è¾“å…¥è¿›è¡Œè‡ªé€‚åº”å¹³å‡æ± åŒ–å¹¶è°ƒæ•´å½¢çŠ¶
        y = self.fc(y).view(b, self.oup * 2, 1, 1)  # é€šè¿‡å…¨è¿æ¥å±‚å¹¶è°ƒæ•´å½¢çŠ¶

        # ä»yä¸­åˆ†ç¦»å‡ºä¸¤ä¸ªæ¿€æ´»å¼ºåº¦å’Œåç½®
        a1, b1 = torch.split(y, self.oup, dim=1)
        a1 = (a1 - 0.5) * self.lambda_a + 1.0  # è®¡ç®—åŠ¨æ€æ¿€æ´»å¼ºåº¦
        out = x * a1 + b1  # è®¡ç®—è¾“å‡º

        return out  # è¿”å›åŠ¨æ€æ¿€æ´»åçš„è¾“å‡º

class DyDCNv2(nn.Module):
    """å¸¦æœ‰å½’ä¸€åŒ–å±‚çš„ModulatedDeformConv2dæ¨¡å—ã€‚"""
    def __init__(self, in_channels, out_channels, stride=1, norm_cfg=dict(type='GN', num_groups=16)):
        super().__init__()
        self.conv = ModulatedDeformConv2d(in_channels, out_channels, 3, stride=stride, padding=1)  # å®šä¹‰å¯è°ƒå˜å½¢å·ç§¯å±‚
        self.norm = build_norm_layer(norm_cfg, out_channels)[1] if norm_cfg else None  # æ ¹æ®é…ç½®æ„å»ºå½’ä¸€åŒ–å±‚

    def forward(self, x, offset, mask):
        """å‰å‘ä¼ æ’­å‡½æ•°ï¼Œè®¡ç®—å·ç§¯è¾“å‡ºã€‚"""
        x = self.conv(x.contiguous(), offset, mask)  # è¿›è¡Œå·ç§¯æ“ä½œ
        if self.norm:
            x = self.norm(x)  # å¦‚æœæœ‰å½’ä¸€åŒ–å±‚ï¼Œåˆ™è¿›è¡Œå½’ä¸€åŒ–
        return x  # è¿”å›å·ç§¯åçš„è¾“å‡º

class DyHeadBlock_Prune(nn.Module):
    """åŒ…å«ä¸‰ç§æ³¨æ„åŠ›æœºåˆ¶çš„DyHeadæ¨¡å—ã€‚"""
    def __init__(self, in_channels, norm_type='GN'):
        super().__init__()
        self.spatial_conv_high = DyDCNv2(in_channels, in_channels)  # é«˜å±‚ç‰¹å¾å·ç§¯
        self.spatial_conv_mid = DyDCNv2(in_channels, in_channels)  # ä¸­å±‚ç‰¹å¾å·ç§¯
        self.spatial_conv_low = DyDCNv2(in_channels, in_channels, stride=2)  # ä½å±‚ç‰¹å¾å·ç§¯
        self.spatial_conv_offset = nn.Conv2d(in_channels, 27, 3, padding=1)  # è®¡ç®—åç§»å’Œæ©ç çš„å·ç§¯å±‚
        self.task_attn_module = DyReLU(in_channels)  # ä»»åŠ¡æ³¨æ„åŠ›æ¨¡å—

    def forward(self, x, level):
        """å‰å‘ä¼ æ’­å‡½æ•°ï¼Œè®¡ç®—ä¸åŒå±‚æ¬¡ç‰¹å¾çš„èåˆã€‚"""
        offset_and_mask = self.spatial_conv_offset(x[level])  # è®¡ç®—åç§»å’Œæ©ç 
        offset = offset_and_mask[:, :18, :, :]  # æå–åç§»
        mask = offset_and_mask[:, 18:, :, :].sigmoid()  # æå–æ©ç å¹¶åº”ç”¨sigmoid

        mid_feat = self.spatial_conv_mid(x[level], offset, mask)  # ä¸­å±‚ç‰¹å¾å·ç§¯
        sum_feat = mid_feat  # åˆå§‹åŒ–ç‰¹å¾å’Œ

        # å¦‚æœæœ‰ä½å±‚ç‰¹å¾ï¼Œåˆ™è¿›è¡Œå·ç§¯å¹¶åŠ æƒ
        if level > 0:
            low_feat = self.spatial_conv_low(x[level - 1], offset, mask)
            sum_feat += low_feat

        # å¦‚æœæœ‰é«˜å±‚ç‰¹å¾ï¼Œåˆ™è¿›è¡Œå·ç§¯å¹¶åŠ æƒ
        if level < len(x) - 1:
            high_feat = F.interpolate(self.spatial_conv_high(x[level + 1], offset, mask), size=x[level].shape[-2:], mode='bilinear', align_corners=True)
            sum_feat += high_feat

        return self.task_attn_module(sum_feat)  # è¿”å›ç»è¿‡ä»»åŠ¡æ³¨æ„åŠ›æ¨¡å—å¤„ç†çš„ç‰¹å¾
```

### ä»£ç æ ¸å¿ƒéƒ¨åˆ†è¯´æ˜ï¼š
1. **DyReLU**ï¼šå®ç°äº†åŠ¨æ€ReLUæ¿€æ´»å‡½æ•°ï¼Œå¯ä»¥æ ¹æ®è¾“å…¥è‡ªé€‚åº”è°ƒæ•´æ¿€æ´»å¼ºåº¦å’Œåç½®ã€‚
2. **DyDCNv2**ï¼šå®ç°äº†å¸¦æœ‰å½’ä¸€åŒ–å±‚çš„å¯è°ƒå˜å½¢å·ç§¯ï¼Œèƒ½å¤Ÿæ ¹æ®è¾“å…¥ç‰¹å¾è®¡ç®—åç§»å’Œæ©ç ã€‚
3. **DyHeadBlock_Prune**ï¼šé›†æˆäº†å¤šä¸ªå·ç§¯å±‚å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œèƒ½å¤Ÿå¤„ç†ä¸åŒå±‚æ¬¡çš„ç‰¹å¾å¹¶è¿›è¡Œèåˆï¼Œæœ€ç»ˆè¾“å‡ºç»è¿‡æ³¨æ„åŠ›æœºåˆ¶åŠ æƒçš„ç‰¹å¾ã€‚

è¿™ä¸ªç¨‹åºæ–‡ä»¶ `dyhead_prune.py` æ˜¯ä¸€ä¸ªåŸºäº PyTorch çš„æ·±åº¦å­¦ä¹ æ¨¡å—ï¼Œä¸»è¦ç”¨äºå®ç°åŠ¨æ€å¤´éƒ¨ï¼ˆDynamic Headï¼‰ä¸­çš„ä¸€äº›è‡ªå®šä¹‰æ¿€æ´»å‡½æ•°å’Œå·ç§¯æ“ä½œã€‚æ–‡ä»¶ä¸­å®šä¹‰äº†å¤šä¸ªç±»ï¼Œæ¯ä¸ªç±»å®ç°äº†ç‰¹å®šçš„åŠŸèƒ½ï¼Œä»¥ä¸‹æ˜¯å¯¹ä»£ç çš„è¯¦ç»†è®²è§£ã€‚

é¦–å…ˆï¼Œæ–‡ä»¶å¯¼å…¥äº†å¿…è¦çš„åº“ï¼ŒåŒ…æ‹¬ PyTorch çš„æ ¸å¿ƒåº“å’Œä¸€äº›åŠŸèƒ½æ¨¡å—ï¼Œå¦‚å·ç§¯ã€æ¿€æ´»å‡½æ•°ç­‰ã€‚å®ƒè¿˜å°è¯•ä» `mmcv` å’Œ `mmengine` å¯¼å…¥ä¸€äº›åŠŸèƒ½ï¼Œå¦‚æœå¯¼å…¥å¤±è´¥åˆ™æ•è·å¼‚å¸¸ã€‚

æ¥ä¸‹æ¥ï¼Œå®šä¹‰äº†ä¸€ä¸ª `_make_divisible` å‡½æ•°ï¼Œç”¨äºç¡®ä¿æŸä¸ªå€¼å¯ä»¥è¢«æŒ‡å®šçš„é™¤æ•°æ•´é™¤ï¼Œå¹¶ä¸”åœ¨å¿…è¦æ—¶å¯¹å…¶è¿›è¡Œè°ƒæ•´ï¼Œä»¥é¿å…è¿‡å¤§çš„å˜åŒ–ã€‚

ç„¶åï¼Œå®šä¹‰äº†å‡ ä¸ªè‡ªå®šä¹‰çš„æ¿€æ´»å‡½æ•°ç±»ï¼ŒåŒ…æ‹¬ `swish`ã€`h_swish` å’Œ `h_sigmoid`ã€‚è¿™äº›ç±»ç»§æ‰¿è‡ª `nn.Module`ï¼Œå¹¶å®ç°äº† `forward` æ–¹æ³•ï¼Œå®šä¹‰äº†å®ƒä»¬å„è‡ªçš„å‰å‘ä¼ æ’­é€»è¾‘ã€‚

`DyReLU` ç±»æ˜¯ä¸€ä¸ªåŠ¨æ€æ¿€æ´»å‡½æ•°ï¼Œå…·æœ‰å¯è°ƒçš„å‚æ•°å’Œå¯é€‰çš„ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶ã€‚å®ƒçš„æ„é€ å‡½æ•°æ¥å—å¤šä¸ªå‚æ•°ï¼ŒåŒ…æ‹¬è¾“å…¥é€šé“æ•°ã€ç¼©å‡æ¯”ä¾‹ã€åˆå§‹åŒ–å‚æ•°ç­‰ã€‚`forward` æ–¹æ³•ä¸­æ ¹æ®è¾“å…¥çš„ç‰¹å¾å›¾è®¡ç®—åŠ¨æ€æ¿€æ´»å€¼ï¼Œå¹¶æ ¹æ®æ¡ä»¶é€‰æ‹©ä¸åŒçš„è¾“å‡ºæ–¹å¼ã€‚

`DyDCNv2` ç±»æ˜¯ä¸€ä¸ªå°è£…äº†è°ƒåˆ¶å˜å½¢å·ç§¯ï¼ˆModulated Deformable Convolutionï¼‰çš„æ¨¡å—ï¼Œæ”¯æŒå¯é€‰çš„å½’ä¸€åŒ–å±‚ã€‚å®ƒçš„æ„é€ å‡½æ•°æ¥å—è¾“å…¥å’Œè¾“å‡ºé€šé“æ•°ã€æ­¥å¹…ä»¥åŠå½’ä¸€åŒ–é…ç½®ï¼Œå¹¶åœ¨å‰å‘ä¼ æ’­ä¸­æ‰§è¡Œå·ç§¯æ“ä½œã€‚

`DyHeadBlock_Prune` ç±»æ˜¯åŠ¨æ€å¤´éƒ¨çš„ä¸»è¦æ¨¡å—ï¼ŒåŒ…å«äº†å¤šä¸ªå·ç§¯å±‚å’Œæ³¨æ„åŠ›æœºåˆ¶ã€‚å®ƒçš„æ„é€ å‡½æ•°åˆå§‹åŒ–äº†å¤šä¸ªå·ç§¯å±‚å’Œæ³¨æ„åŠ›æ¨¡å—ï¼Œå¹¶å®šä¹‰äº†æƒé‡åˆå§‹åŒ–çš„æ–¹æ³•ã€‚`forward` æ–¹æ³•è®¡ç®—è¾“å…¥ç‰¹å¾å›¾çš„åç§»é‡å’Œæ©ç ï¼Œå¹¶é€šè¿‡ä¸åŒçš„å·ç§¯å±‚å¤„ç†ç‰¹å¾å›¾ï¼Œæœ€ç»ˆç»“åˆä¸åŒå±‚æ¬¡çš„ç‰¹å¾è¿›è¡Œè¾“å‡ºã€‚

æ•´ä¸ªæ–‡ä»¶çš„ç»“æ„æ¸…æ™°ï¼ŒåŠŸèƒ½æ¨¡å—åŒ–ï¼Œé€‚åˆåœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­ä½¿ç”¨ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦åŠ¨æ€è°ƒæ•´ç‰¹å¾å›¾çš„æƒ…å†µä¸‹ã€‚é€šè¿‡è¿™äº›è‡ªå®šä¹‰çš„æ¿€æ´»å‡½æ•°å’Œå·ç§¯æ“ä½œï¼Œå¯ä»¥å®ç°æ›´çµæ´»çš„ç‰¹å¾æå–å’Œè¡¨ç¤ºå­¦ä¹ ã€‚

### 11.å®Œæ•´è®­ç»ƒ+Webå‰ç«¯ç•Œé¢+200+ç§å…¨å¥—åˆ›æ–°ç‚¹æºç ã€æ•°æ®é›†è·å–

![19.png](19.png)


# [ä¸‹è½½é“¾æ¥ï¼šhttps://mbd.pub/o/bread/Z5yYk55v](https://mbd.pub/o/bread/Z5yYk55v)